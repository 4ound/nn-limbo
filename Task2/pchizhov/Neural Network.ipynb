{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1, -2, 3],\n",
    "              [-1, 2, 0.1]])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301685, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301851, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301124, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302831, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301638, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302170, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302807, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302832, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303278, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302333, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302433, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301941, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302173, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11b2af128>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.275985, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.347515, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264348, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253264, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265011, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302624, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311032, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234316, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.353994, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.378711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256101, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264767, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274562, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.322051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317549, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262630, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308261, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264990, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278636, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276510, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314133, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256404, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278750, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280567, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240982, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315651, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351801, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319693, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.295926, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.345443, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.310013, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.326544, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.255641, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.199259, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.164561, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.025661, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.883798, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.263931, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.662918, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.245522, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.943906, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.663953, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.042200, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.418303, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.519709, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.823944, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.022291, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.585656, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.937038, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.908215, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.233499, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.095108, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.718242, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.162756, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.015933, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.363952, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.842670, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.657567, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.388463, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.911120, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.693765, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.010436, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.115900, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.613706, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.738574, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.885192, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 2.474042, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.119274, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.672047, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.767860, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.478802, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.926619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.337383, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.683186, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.660081, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.401881, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.635264, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.635617, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.622938, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.854111, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.556636, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634732, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.076198, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.007559, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.531114, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.041336, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.022564, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.647379, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.369538, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.379903, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.986917, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.318972, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.283966, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.936269, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.196061, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.739352, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634901, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.201189, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.582981, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.742143, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.293135, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.748190, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.976545, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.357876, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.992895, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602046, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602167, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.173057, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.312798, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.564551, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.961713, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.274091, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.304703, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.958926, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.377168, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.657193, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.389767, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.576803, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.556738, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.175409, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.322616, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.251510, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.060407, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.661861, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.227308, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.597969, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.887250, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.338688, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.842966, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.160604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.347215, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.223119, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.436648, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.535320, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.249121, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.248964, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.549803, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.259687, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.097239, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.324286, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.315431, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.420746, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.443017, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.301618, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.533658, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.607993, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.239065, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.649177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.174445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.602848, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.363682, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.160640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.197888, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.126413, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.008120, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.643235, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.592807, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.412599, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.212850, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.196541, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.280346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.403204, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229377, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.400568, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.391042, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.102808, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.445285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.406323, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219193, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.449330, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.304464, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.494726, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.327706, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.361608, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.460816, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.424061, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.372024, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.399797, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.448276, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.436993, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.164884, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.751487, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 0.463355, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 0.405336, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.074943, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.218037, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.452415, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.234652, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 2.323422, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.488904, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 2.339894, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.289522, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.210798, Train accuracy: 0.866667, val accuracy: 0.133333\n",
      "Loss: 0.789584, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.104253, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.400592, Train accuracy: 1.000000, val accuracy: 0.066667\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=2)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.249926, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238984, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243590, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.191894, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284740, Train accuracy: 0.222111, val accuracy: 0.231000\n",
      "Loss: 1.883675, Train accuracy: 0.266333, val accuracy: 0.261000\n",
      "Loss: 1.846817, Train accuracy: 0.292222, val accuracy: 0.299000\n",
      "Loss: 1.900490, Train accuracy: 0.364889, val accuracy: 0.365000\n",
      "Loss: 1.872081, Train accuracy: 0.410778, val accuracy: 0.391000\n",
      "Loss: 1.493535, Train accuracy: 0.456444, val accuracy: 0.450000\n",
      "Loss: 1.654169, Train accuracy: 0.485778, val accuracy: 0.487000\n",
      "Loss: 1.412783, Train accuracy: 0.532111, val accuracy: 0.524000\n",
      "Loss: 1.266303, Train accuracy: 0.557556, val accuracy: 0.552000\n",
      "Loss: 1.536600, Train accuracy: 0.598000, val accuracy: 0.584000\n",
      "Loss: 0.952769, Train accuracy: 0.626111, val accuracy: 0.594000\n",
      "Loss: 1.168268, Train accuracy: 0.635111, val accuracy: 0.627000\n",
      "Loss: 0.958693, Train accuracy: 0.641333, val accuracy: 0.617000\n",
      "Loss: 1.644236, Train accuracy: 0.666000, val accuracy: 0.646000\n",
      "Loss: 1.057625, Train accuracy: 0.676556, val accuracy: 0.640000\n",
      "Loss: 0.942437, Train accuracy: 0.686889, val accuracy: 0.671000\n",
      "Loss: 1.347948, Train accuracy: 0.690000, val accuracy: 0.667000\n",
      "Loss: 1.140404, Train accuracy: 0.707556, val accuracy: 0.684000\n",
      "Loss: 1.188997, Train accuracy: 0.706778, val accuracy: 0.671000\n",
      "Loss: 1.103939, Train accuracy: 0.720333, val accuracy: 0.681000\n",
      "Loss: 0.995245, Train accuracy: 0.724444, val accuracy: 0.691000\n",
      "Loss: 1.010881, Train accuracy: 0.728111, val accuracy: 0.694000\n",
      "Loss: 1.130314, Train accuracy: 0.738889, val accuracy: 0.702000\n",
      "Loss: 0.834474, Train accuracy: 0.743111, val accuracy: 0.702000\n",
      "Loss: 0.936800, Train accuracy: 0.752889, val accuracy: 0.708000\n",
      "Loss: 1.075953, Train accuracy: 0.760889, val accuracy: 0.713000\n",
      "Loss: 0.708508, Train accuracy: 0.765778, val accuracy: 0.709000\n",
      "Loss: 0.984572, Train accuracy: 0.763667, val accuracy: 0.698000\n",
      "Loss: 0.657265, Train accuracy: 0.767778, val accuracy: 0.718000\n",
      "Loss: 0.803103, Train accuracy: 0.776333, val accuracy: 0.713000\n",
      "Loss: 1.050644, Train accuracy: 0.783778, val accuracy: 0.712000\n",
      "Loss: 0.950094, Train accuracy: 0.787444, val accuracy: 0.725000\n",
      "Loss: 0.794083, Train accuracy: 0.791667, val accuracy: 0.724000\n",
      "Loss: 1.189879, Train accuracy: 0.779778, val accuracy: 0.710000\n",
      "Loss: 1.215250, Train accuracy: 0.796444, val accuracy: 0.716000\n",
      "Loss: 1.163973, Train accuracy: 0.795889, val accuracy: 0.731000\n",
      "Loss: 0.795222, Train accuracy: 0.803444, val accuracy: 0.730000\n",
      "Loss: 0.997248, Train accuracy: 0.813778, val accuracy: 0.733000\n",
      "Loss: 0.924778, Train accuracy: 0.805333, val accuracy: 0.725000\n",
      "Loss: 0.857621, Train accuracy: 0.817444, val accuracy: 0.741000\n",
      "Loss: 0.865618, Train accuracy: 0.823111, val accuracy: 0.742000\n",
      "Loss: 1.252778, Train accuracy: 0.825333, val accuracy: 0.742000\n",
      "Loss: 0.938488, Train accuracy: 0.829889, val accuracy: 0.742000\n",
      "Loss: 0.955428, Train accuracy: 0.831222, val accuracy: 0.727000\n",
      "Loss: 0.839648, Train accuracy: 0.841556, val accuracy: 0.743000\n",
      "Loss: 0.806345, Train accuracy: 0.823556, val accuracy: 0.722000\n",
      "Loss: 0.910118, Train accuracy: 0.836889, val accuracy: 0.729000\n",
      "Loss: 0.818778, Train accuracy: 0.847667, val accuracy: 0.745000\n",
      "Loss: 0.736316, Train accuracy: 0.840000, val accuracy: 0.726000\n",
      "Loss: 1.138122, Train accuracy: 0.852333, val accuracy: 0.740000\n",
      "Loss: 0.752368, Train accuracy: 0.844000, val accuracy: 0.748000\n",
      "Loss: 0.890759, Train accuracy: 0.858000, val accuracy: 0.759000\n",
      "Loss: 0.794953, Train accuracy: 0.859000, val accuracy: 0.748000\n",
      "Loss: 0.879445, Train accuracy: 0.858111, val accuracy: 0.751000\n",
      "Loss: 0.983078, Train accuracy: 0.856222, val accuracy: 0.748000\n",
      "Loss: 0.778933, Train accuracy: 0.871556, val accuracy: 0.758000\n",
      "Loss: 0.738461, Train accuracy: 0.864889, val accuracy: 0.747000\n",
      "Loss: 0.741108, Train accuracy: 0.855444, val accuracy: 0.744000\n",
      "Loss: 0.892519, Train accuracy: 0.879000, val accuracy: 0.752000\n",
      "Loss: 0.923557, Train accuracy: 0.881000, val accuracy: 0.750000\n",
      "Loss: 0.969196, Train accuracy: 0.882333, val accuracy: 0.759000\n",
      "Loss: 1.016104, Train accuracy: 0.866889, val accuracy: 0.745000\n",
      "Loss: 1.069196, Train accuracy: 0.869000, val accuracy: 0.750000\n",
      "Loss: 0.970589, Train accuracy: 0.888222, val accuracy: 0.757000\n",
      "Loss: 0.804645, Train accuracy: 0.885556, val accuracy: 0.753000\n",
      "Loss: 0.832040, Train accuracy: 0.877889, val accuracy: 0.748000\n",
      "Loss: 0.880110, Train accuracy: 0.874111, val accuracy: 0.756000\n",
      "Loss: 0.804496, Train accuracy: 0.887000, val accuracy: 0.745000\n",
      "Loss: 1.287700, Train accuracy: 0.869556, val accuracy: 0.733000\n",
      "Loss: 0.828273, Train accuracy: 0.883222, val accuracy: 0.753000\n",
      "Loss: 0.862238, Train accuracy: 0.889222, val accuracy: 0.747000\n",
      "Loss: 0.636525, Train accuracy: 0.897000, val accuracy: 0.746000\n",
      "Loss: 0.663136, Train accuracy: 0.892333, val accuracy: 0.744000\n",
      "Loss: 0.832859, Train accuracy: 0.903667, val accuracy: 0.754000\n",
      "Loss: 0.823605, Train accuracy: 0.901889, val accuracy: 0.746000\n",
      "Loss: 0.812294, Train accuracy: 0.894556, val accuracy: 0.744000\n",
      "Loss: 0.904070, Train accuracy: 0.904222, val accuracy: 0.745000\n",
      "Loss: 0.885880, Train accuracy: 0.902778, val accuracy: 0.754000\n",
      "Loss: 1.144320, Train accuracy: 0.910222, val accuracy: 0.752000\n",
      "Loss: 1.232233, Train accuracy: 0.882556, val accuracy: 0.736000\n",
      "Loss: 0.797343, Train accuracy: 0.900444, val accuracy: 0.742000\n",
      "Loss: 0.948918, Train accuracy: 0.917111, val accuracy: 0.765000\n",
      "Loss: 0.859769, Train accuracy: 0.913222, val accuracy: 0.752000\n",
      "Loss: 1.099685, Train accuracy: 0.912333, val accuracy: 0.750000\n",
      "Loss: 0.980936, Train accuracy: 0.918111, val accuracy: 0.757000\n",
      "Loss: 0.880861, Train accuracy: 0.908444, val accuracy: 0.743000\n",
      "Loss: 0.733101, Train accuracy: 0.919222, val accuracy: 0.757000\n",
      "Loss: 0.824601, Train accuracy: 0.919778, val accuracy: 0.760000\n",
      "Loss: 0.862637, Train accuracy: 0.921444, val accuracy: 0.755000\n",
      "Loss: 0.854465, Train accuracy: 0.919000, val accuracy: 0.747000\n",
      "Loss: 0.887911, Train accuracy: 0.923000, val accuracy: 0.753000\n",
      "Loss: 0.892553, Train accuracy: 0.922889, val accuracy: 0.754000\n",
      "Loss: 0.944497, Train accuracy: 0.928556, val accuracy: 0.757000\n",
      "Loss: 0.869076, Train accuracy: 0.929000, val accuracy: 0.743000\n",
      "Loss: 0.802507, Train accuracy: 0.926556, val accuracy: 0.754000\n",
      "Loss: 0.957931, Train accuracy: 0.921444, val accuracy: 0.752000\n",
      "Loss: 0.883421, Train accuracy: 0.933667, val accuracy: 0.761000\n",
      "Loss: 0.865494, Train accuracy: 0.927444, val accuracy: 0.744000\n",
      "Loss: 0.905757, Train accuracy: 0.931778, val accuracy: 0.764000\n",
      "Loss: 1.159166, Train accuracy: 0.929778, val accuracy: 0.755000\n",
      "Loss: 0.882924, Train accuracy: 0.934667, val accuracy: 0.744000\n",
      "Loss: 1.076535, Train accuracy: 0.923333, val accuracy: 0.738000\n",
      "Loss: 0.862737, Train accuracy: 0.930556, val accuracy: 0.756000\n",
      "Loss: 1.058118, Train accuracy: 0.932222, val accuracy: 0.760000\n",
      "Loss: 1.169388, Train accuracy: 0.932556, val accuracy: 0.755000\n",
      "Loss: 0.994481, Train accuracy: 0.937889, val accuracy: 0.752000\n",
      "Loss: 0.993108, Train accuracy: 0.934444, val accuracy: 0.751000\n",
      "Loss: 0.950195, Train accuracy: 0.934111, val accuracy: 0.753000\n",
      "Loss: 0.953167, Train accuracy: 0.934667, val accuracy: 0.743000\n",
      "Loss: 0.895758, Train accuracy: 0.940667, val accuracy: 0.753000\n",
      "Loss: 1.129986, Train accuracy: 0.936111, val accuracy: 0.745000\n",
      "Loss: 0.890184, Train accuracy: 0.940000, val accuracy: 0.751000\n",
      "Loss: 0.856721, Train accuracy: 0.944111, val accuracy: 0.757000\n",
      "Loss: 0.896550, Train accuracy: 0.938222, val accuracy: 0.759000\n",
      "Loss: 1.022617, Train accuracy: 0.941778, val accuracy: 0.761000\n",
      "Loss: 0.901250, Train accuracy: 0.947333, val accuracy: 0.765000\n",
      "Loss: 0.925774, Train accuracy: 0.947333, val accuracy: 0.755000\n",
      "Loss: 0.914981, Train accuracy: 0.950111, val accuracy: 0.753000\n",
      "Loss: 0.947059, Train accuracy: 0.949778, val accuracy: 0.756000\n",
      "Loss: 0.963950, Train accuracy: 0.935778, val accuracy: 0.751000\n",
      "Loss: 1.002879, Train accuracy: 0.943667, val accuracy: 0.762000\n",
      "Loss: 0.869629, Train accuracy: 0.950667, val accuracy: 0.750000\n",
      "Loss: 0.902915, Train accuracy: 0.950444, val accuracy: 0.752000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.177648, Train accuracy: 0.944778, val accuracy: 0.758000\n",
      "Loss: 1.057812, Train accuracy: 0.955889, val accuracy: 0.764000\n",
      "Loss: 0.995695, Train accuracy: 0.947333, val accuracy: 0.757000\n",
      "Loss: 0.975293, Train accuracy: 0.953667, val accuracy: 0.744000\n",
      "Loss: 0.983542, Train accuracy: 0.955333, val accuracy: 0.757000\n",
      "Loss: 0.960774, Train accuracy: 0.955444, val accuracy: 0.756000\n",
      "Loss: 0.992938, Train accuracy: 0.962111, val accuracy: 0.764000\n",
      "Loss: 0.908102, Train accuracy: 0.959444, val accuracy: 0.762000\n",
      "Loss: 1.052932, Train accuracy: 0.957889, val accuracy: 0.752000\n",
      "Loss: 0.996247, Train accuracy: 0.954333, val accuracy: 0.760000\n",
      "Loss: 1.069989, Train accuracy: 0.958778, val accuracy: 0.751000\n",
      "Loss: 0.990700, Train accuracy: 0.958000, val accuracy: 0.764000\n",
      "Loss: 1.045251, Train accuracy: 0.957556, val accuracy: 0.754000\n",
      "Loss: 0.978240, Train accuracy: 0.957222, val accuracy: 0.762000\n",
      "Loss: 0.995703, Train accuracy: 0.960111, val accuracy: 0.760000\n",
      "Loss: 1.073932, Train accuracy: 0.966222, val accuracy: 0.754000\n",
      "Loss: 1.096732, Train accuracy: 0.962556, val accuracy: 0.757000\n",
      "Loss: 1.026712, Train accuracy: 0.959889, val accuracy: 0.751000\n",
      "Loss: 0.977087, Train accuracy: 0.962667, val accuracy: 0.756000\n",
      "Loss: 1.063474, Train accuracy: 0.964889, val accuracy: 0.770000\n",
      "Loss: 1.039855, Train accuracy: 0.963667, val accuracy: 0.750000\n",
      "Loss: 1.036073, Train accuracy: 0.966000, val accuracy: 0.760000\n",
      "Loss: 1.163502, Train accuracy: 0.968333, val accuracy: 0.756000\n",
      "Loss: 1.028553, Train accuracy: 0.959000, val accuracy: 0.763000\n",
      "Loss: 1.186056, Train accuracy: 0.965667, val accuracy: 0.756000\n",
      "Loss: 1.028844, Train accuracy: 0.964889, val accuracy: 0.757000\n",
      "Loss: 1.083078, Train accuracy: 0.967444, val accuracy: 0.756000\n",
      "Loss: 1.037450, Train accuracy: 0.968667, val accuracy: 0.758000\n",
      "Loss: 1.116246, Train accuracy: 0.965778, val accuracy: 0.759000\n",
      "Loss: 1.011999, Train accuracy: 0.968556, val accuracy: 0.754000\n",
      "Loss: 1.092448, Train accuracy: 0.967778, val accuracy: 0.755000\n",
      "Loss: 1.073254, Train accuracy: 0.967889, val accuracy: 0.758000\n",
      "Loss: 1.067205, Train accuracy: 0.972333, val accuracy: 0.750000\n",
      "Loss: 1.093677, Train accuracy: 0.968889, val accuracy: 0.745000\n",
      "Loss: 1.172546, Train accuracy: 0.971333, val accuracy: 0.760000\n",
      "Loss: 1.008322, Train accuracy: 0.973222, val accuracy: 0.748000\n",
      "Loss: 1.117283, Train accuracy: 0.976333, val accuracy: 0.753000\n",
      "Loss: 1.094899, Train accuracy: 0.973222, val accuracy: 0.760000\n",
      "Loss: 1.205320, Train accuracy: 0.970889, val accuracy: 0.750000\n",
      "Loss: 1.185042, Train accuracy: 0.967333, val accuracy: 0.753000\n",
      "Loss: 1.195974, Train accuracy: 0.969667, val accuracy: 0.756000\n",
      "Loss: 1.091907, Train accuracy: 0.974556, val accuracy: 0.760000\n",
      "Loss: 1.376654, Train accuracy: 0.973444, val accuracy: 0.757000\n",
      "Loss: 1.164087, Train accuracy: 0.968222, val accuracy: 0.751000\n",
      "Loss: 1.089115, Train accuracy: 0.978222, val accuracy: 0.766000\n",
      "Loss: 1.260140, Train accuracy: 0.978667, val accuracy: 0.757000\n",
      "Loss: 1.170174, Train accuracy: 0.965000, val accuracy: 0.755000\n",
      "Loss: 1.223673, Train accuracy: 0.973556, val accuracy: 0.759000\n",
      "Loss: 1.128962, Train accuracy: 0.977222, val accuracy: 0.754000\n",
      "Loss: 1.082807, Train accuracy: 0.977333, val accuracy: 0.753000\n",
      "Loss: 1.101247, Train accuracy: 0.980111, val accuracy: 0.756000\n",
      "Loss: 1.223625, Train accuracy: 0.963556, val accuracy: 0.758000\n",
      "Loss: 1.194635, Train accuracy: 0.979000, val accuracy: 0.756000\n",
      "Loss: 1.316568, Train accuracy: 0.976000, val accuracy: 0.756000\n",
      "Loss: 1.163785, Train accuracy: 0.980444, val accuracy: 0.753000\n",
      "Loss: 1.237178, Train accuracy: 0.969889, val accuracy: 0.751000\n",
      "Loss: 1.245498, Train accuracy: 0.980667, val accuracy: 0.755000\n",
      "Loss: 1.255696, Train accuracy: 0.982222, val accuracy: 0.766000\n",
      "Loss: 1.207468, Train accuracy: 0.949444, val accuracy: 0.735000\n",
      "Loss: 1.209629, Train accuracy: 0.985000, val accuracy: 0.758000\n",
      "Loss: 1.131891, Train accuracy: 0.980222, val accuracy: 0.752000\n",
      "Loss: 1.215032, Train accuracy: 0.983111, val accuracy: 0.764000\n",
      "Loss: 1.227741, Train accuracy: 0.973889, val accuracy: 0.748000\n",
      "Loss: 1.327548, Train accuracy: 0.981889, val accuracy: 0.758000\n",
      "Loss: 1.213307, Train accuracy: 0.979556, val accuracy: 0.756000\n",
      "Loss: 1.331596, Train accuracy: 0.979444, val accuracy: 0.751000\n",
      "Loss: 1.217891, Train accuracy: 0.984444, val accuracy: 0.750000\n",
      "Loss: 1.255397, Train accuracy: 0.980111, val accuracy: 0.756000\n",
      "Loss: 1.237216, Train accuracy: 0.980000, val accuracy: 0.756000\n",
      "Loss: 1.156532, Train accuracy: 0.982000, val accuracy: 0.755000\n",
      "Loss: 1.176837, Train accuracy: 0.984000, val accuracy: 0.747000\n",
      "Loss: 1.179666, Train accuracy: 0.983556, val accuracy: 0.754000\n",
      "Loss: 1.356902, Train accuracy: 0.973333, val accuracy: 0.749000\n",
      "Loss: 2.209077, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230034, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.137118, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.167458, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.059147, Train accuracy: 0.238111, val accuracy: 0.243000\n",
      "Loss: 2.043671, Train accuracy: 0.277444, val accuracy: 0.277000\n",
      "Loss: 1.943141, Train accuracy: 0.313556, val accuracy: 0.324000\n",
      "Loss: 1.760626, Train accuracy: 0.378889, val accuracy: 0.378000\n",
      "Loss: 1.987968, Train accuracy: 0.434333, val accuracy: 0.440000\n",
      "Loss: 1.432690, Train accuracy: 0.481222, val accuracy: 0.481000\n",
      "Loss: 1.525986, Train accuracy: 0.522111, val accuracy: 0.518000\n",
      "Loss: 1.428011, Train accuracy: 0.538222, val accuracy: 0.527000\n",
      "Loss: 1.464750, Train accuracy: 0.589778, val accuracy: 0.575000\n",
      "Loss: 1.149250, Train accuracy: 0.617333, val accuracy: 0.605000\n",
      "Loss: 1.036309, Train accuracy: 0.640556, val accuracy: 0.629000\n",
      "Loss: 1.118185, Train accuracy: 0.661889, val accuracy: 0.639000\n",
      "Loss: 1.279211, Train accuracy: 0.672778, val accuracy: 0.659000\n",
      "Loss: 1.143305, Train accuracy: 0.681333, val accuracy: 0.670000\n",
      "Loss: 0.795660, Train accuracy: 0.695667, val accuracy: 0.674000\n",
      "Loss: 1.512693, Train accuracy: 0.684000, val accuracy: 0.668000\n",
      "Loss: 1.363058, Train accuracy: 0.715222, val accuracy: 0.685000\n",
      "Loss: 1.252879, Train accuracy: 0.735222, val accuracy: 0.711000\n",
      "Loss: 1.165572, Train accuracy: 0.741222, val accuracy: 0.706000\n",
      "Loss: 1.211807, Train accuracy: 0.743778, val accuracy: 0.711000\n",
      "Loss: 0.897420, Train accuracy: 0.751667, val accuracy: 0.708000\n",
      "Loss: 1.092132, Train accuracy: 0.760667, val accuracy: 0.709000\n",
      "Loss: 1.230708, Train accuracy: 0.760667, val accuracy: 0.711000\n",
      "Loss: 0.850552, Train accuracy: 0.768333, val accuracy: 0.713000\n",
      "Loss: 0.995402, Train accuracy: 0.779556, val accuracy: 0.718000\n",
      "Loss: 0.708430, Train accuracy: 0.775889, val accuracy: 0.713000\n",
      "Loss: 0.793494, Train accuracy: 0.787444, val accuracy: 0.716000\n",
      "Loss: 0.932062, Train accuracy: 0.789889, val accuracy: 0.710000\n",
      "Loss: 0.892569, Train accuracy: 0.799778, val accuracy: 0.717000\n",
      "Loss: 0.812572, Train accuracy: 0.804667, val accuracy: 0.722000\n",
      "Loss: 1.059539, Train accuracy: 0.806667, val accuracy: 0.727000\n",
      "Loss: 0.959813, Train accuracy: 0.801111, val accuracy: 0.716000\n",
      "Loss: 0.759943, Train accuracy: 0.819556, val accuracy: 0.722000\n",
      "Loss: 1.034550, Train accuracy: 0.824111, val accuracy: 0.730000\n",
      "Loss: 0.965539, Train accuracy: 0.819111, val accuracy: 0.723000\n",
      "Loss: 0.922453, Train accuracy: 0.834111, val accuracy: 0.733000\n",
      "Loss: 0.663166, Train accuracy: 0.838556, val accuracy: 0.741000\n",
      "Loss: 0.817184, Train accuracy: 0.830778, val accuracy: 0.743000\n",
      "Loss: 0.784679, Train accuracy: 0.836222, val accuracy: 0.737000\n",
      "Loss: 0.744848, Train accuracy: 0.839889, val accuracy: 0.738000\n",
      "Loss: 0.780025, Train accuracy: 0.846000, val accuracy: 0.748000\n",
      "Loss: 0.956543, Train accuracy: 0.853111, val accuracy: 0.752000\n",
      "Loss: 0.756167, Train accuracy: 0.860556, val accuracy: 0.740000\n",
      "Loss: 0.933091, Train accuracy: 0.853556, val accuracy: 0.739000\n",
      "Loss: 0.856664, Train accuracy: 0.867444, val accuracy: 0.754000\n",
      "Loss: 0.767326, Train accuracy: 0.870444, val accuracy: 0.752000\n",
      "Loss: 0.608099, Train accuracy: 0.865333, val accuracy: 0.740000\n",
      "Loss: 0.944797, Train accuracy: 0.871222, val accuracy: 0.746000\n",
      "Loss: 0.853837, Train accuracy: 0.867111, val accuracy: 0.736000\n",
      "Loss: 0.887418, Train accuracy: 0.878667, val accuracy: 0.752000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.889701, Train accuracy: 0.882778, val accuracy: 0.746000\n",
      "Loss: 0.685810, Train accuracy: 0.885889, val accuracy: 0.752000\n",
      "Loss: 0.734207, Train accuracy: 0.883556, val accuracy: 0.749000\n",
      "Loss: 0.882070, Train accuracy: 0.871333, val accuracy: 0.746000\n",
      "Loss: 0.690369, Train accuracy: 0.893444, val accuracy: 0.749000\n",
      "Loss: 0.748438, Train accuracy: 0.889111, val accuracy: 0.758000\n",
      "Loss: 1.155927, Train accuracy: 0.892000, val accuracy: 0.743000\n",
      "Loss: 0.861599, Train accuracy: 0.904667, val accuracy: 0.763000\n",
      "Loss: 0.676927, Train accuracy: 0.907778, val accuracy: 0.752000\n",
      "Loss: 0.767916, Train accuracy: 0.901667, val accuracy: 0.751000\n",
      "Loss: 0.782812, Train accuracy: 0.910778, val accuracy: 0.761000\n",
      "Loss: 0.981543, Train accuracy: 0.913222, val accuracy: 0.758000\n",
      "Loss: 0.958606, Train accuracy: 0.913111, val accuracy: 0.759000\n",
      "Loss: 0.764358, Train accuracy: 0.914556, val accuracy: 0.757000\n",
      "Loss: 0.933364, Train accuracy: 0.920222, val accuracy: 0.762000\n",
      "Loss: 0.737043, Train accuracy: 0.917000, val accuracy: 0.752000\n",
      "Loss: 0.885826, Train accuracy: 0.911889, val accuracy: 0.760000\n",
      "Loss: 0.761490, Train accuracy: 0.923889, val accuracy: 0.763000\n",
      "Loss: 0.801545, Train accuracy: 0.918333, val accuracy: 0.756000\n",
      "Loss: 0.749582, Train accuracy: 0.930111, val accuracy: 0.763000\n",
      "Loss: 0.946497, Train accuracy: 0.928222, val accuracy: 0.763000\n",
      "Loss: 0.853122, Train accuracy: 0.934333, val accuracy: 0.763000\n",
      "Loss: 0.871194, Train accuracy: 0.923111, val accuracy: 0.755000\n",
      "Loss: 0.770435, Train accuracy: 0.936222, val accuracy: 0.762000\n",
      "Loss: 0.879572, Train accuracy: 0.920111, val accuracy: 0.762000\n",
      "Loss: 0.764789, Train accuracy: 0.931778, val accuracy: 0.762000\n",
      "Loss: 0.857214, Train accuracy: 0.919222, val accuracy: 0.753000\n",
      "Loss: 0.937761, Train accuracy: 0.943111, val accuracy: 0.759000\n",
      "Loss: 1.088289, Train accuracy: 0.938889, val accuracy: 0.760000\n",
      "Loss: 1.048866, Train accuracy: 0.932111, val accuracy: 0.758000\n",
      "Loss: 0.820511, Train accuracy: 0.948778, val accuracy: 0.764000\n",
      "Loss: 0.755402, Train accuracy: 0.934778, val accuracy: 0.764000\n",
      "Loss: 0.840652, Train accuracy: 0.943556, val accuracy: 0.757000\n",
      "Loss: 0.818566, Train accuracy: 0.943667, val accuracy: 0.772000\n",
      "Loss: 0.899782, Train accuracy: 0.950667, val accuracy: 0.755000\n",
      "Loss: 0.804142, Train accuracy: 0.955111, val accuracy: 0.763000\n",
      "Loss: 0.855494, Train accuracy: 0.955333, val accuracy: 0.762000\n",
      "Loss: 0.792282, Train accuracy: 0.949556, val accuracy: 0.759000\n",
      "Loss: 0.920011, Train accuracy: 0.955222, val accuracy: 0.767000\n",
      "Loss: 0.812770, Train accuracy: 0.959889, val accuracy: 0.766000\n",
      "Loss: 0.786575, Train accuracy: 0.896889, val accuracy: 0.725000\n",
      "Loss: 0.927834, Train accuracy: 0.957000, val accuracy: 0.760000\n",
      "Loss: 0.925777, Train accuracy: 0.963889, val accuracy: 0.763000\n",
      "Loss: 0.810702, Train accuracy: 0.960222, val accuracy: 0.768000\n",
      "Loss: 0.912982, Train accuracy: 0.964444, val accuracy: 0.763000\n",
      "Loss: 0.918744, Train accuracy: 0.958111, val accuracy: 0.763000\n",
      "Loss: 0.937718, Train accuracy: 0.958111, val accuracy: 0.765000\n",
      "Loss: 0.889024, Train accuracy: 0.958556, val accuracy: 0.766000\n",
      "Loss: 0.903760, Train accuracy: 0.965111, val accuracy: 0.768000\n",
      "Loss: 0.944352, Train accuracy: 0.964111, val accuracy: 0.771000\n",
      "Loss: 1.078772, Train accuracy: 0.965333, val accuracy: 0.772000\n",
      "Loss: 0.972597, Train accuracy: 0.966333, val accuracy: 0.765000\n",
      "Loss: 0.891261, Train accuracy: 0.946444, val accuracy: 0.766000\n",
      "Loss: 0.897190, Train accuracy: 0.963667, val accuracy: 0.765000\n",
      "Loss: 0.973954, Train accuracy: 0.970222, val accuracy: 0.772000\n",
      "Loss: 0.908049, Train accuracy: 0.970889, val accuracy: 0.764000\n",
      "Loss: 0.994925, Train accuracy: 0.973778, val accuracy: 0.776000\n",
      "Loss: 0.877386, Train accuracy: 0.971111, val accuracy: 0.768000\n",
      "Loss: 0.854829, Train accuracy: 0.971111, val accuracy: 0.770000\n",
      "Loss: 0.832583, Train accuracy: 0.974667, val accuracy: 0.773000\n",
      "Loss: 0.972568, Train accuracy: 0.970889, val accuracy: 0.768000\n",
      "Loss: 1.071910, Train accuracy: 0.971222, val accuracy: 0.768000\n",
      "Loss: 0.933121, Train accuracy: 0.968333, val accuracy: 0.760000\n",
      "Loss: 0.904676, Train accuracy: 0.974667, val accuracy: 0.770000\n",
      "Loss: 0.857495, Train accuracy: 0.966889, val accuracy: 0.757000\n",
      "Loss: 0.927217, Train accuracy: 0.980444, val accuracy: 0.766000\n",
      "Loss: 1.048416, Train accuracy: 0.949000, val accuracy: 0.751000\n",
      "Loss: 0.904273, Train accuracy: 0.979889, val accuracy: 0.769000\n",
      "Loss: 1.023577, Train accuracy: 0.980222, val accuracy: 0.773000\n",
      "Loss: 0.953978, Train accuracy: 0.976889, val accuracy: 0.776000\n",
      "Loss: 0.960507, Train accuracy: 0.981222, val accuracy: 0.771000\n",
      "Loss: 0.983141, Train accuracy: 0.972000, val accuracy: 0.756000\n",
      "Loss: 1.043406, Train accuracy: 0.972556, val accuracy: 0.777000\n",
      "Loss: 0.961969, Train accuracy: 0.982889, val accuracy: 0.771000\n",
      "Loss: 1.099815, Train accuracy: 0.982111, val accuracy: 0.769000\n",
      "Loss: 1.002764, Train accuracy: 0.981111, val accuracy: 0.766000\n",
      "Loss: 0.939717, Train accuracy: 0.987000, val accuracy: 0.770000\n",
      "Loss: 0.949836, Train accuracy: 0.986000, val accuracy: 0.763000\n",
      "Loss: 0.960704, Train accuracy: 0.984556, val accuracy: 0.773000\n",
      "Loss: 0.991567, Train accuracy: 0.985889, val accuracy: 0.766000\n",
      "Loss: 0.984833, Train accuracy: 0.984111, val accuracy: 0.764000\n",
      "Loss: 1.086629, Train accuracy: 0.985556, val accuracy: 0.776000\n",
      "Loss: 0.968768, Train accuracy: 0.982889, val accuracy: 0.762000\n",
      "Loss: 1.021339, Train accuracy: 0.986000, val accuracy: 0.771000\n",
      "Loss: 1.080875, Train accuracy: 0.985222, val accuracy: 0.768000\n",
      "Loss: 0.984868, Train accuracy: 0.987778, val accuracy: 0.768000\n",
      "Loss: 0.990285, Train accuracy: 0.987000, val accuracy: 0.768000\n",
      "Loss: 0.975348, Train accuracy: 0.985889, val accuracy: 0.771000\n",
      "Loss: 0.993722, Train accuracy: 0.982556, val accuracy: 0.774000\n",
      "Loss: 1.070501, Train accuracy: 0.986111, val accuracy: 0.771000\n",
      "Loss: 1.097745, Train accuracy: 0.981556, val accuracy: 0.766000\n",
      "Loss: 1.064164, Train accuracy: 0.984667, val accuracy: 0.778000\n",
      "Loss: 0.996686, Train accuracy: 0.991778, val accuracy: 0.771000\n",
      "Loss: 1.132709, Train accuracy: 0.991667, val accuracy: 0.770000\n",
      "Loss: 1.063267, Train accuracy: 0.987778, val accuracy: 0.772000\n",
      "Loss: 1.115050, Train accuracy: 0.985444, val accuracy: 0.773000\n",
      "Loss: 1.079192, Train accuracy: 0.989000, val accuracy: 0.766000\n",
      "Loss: 1.005542, Train accuracy: 0.989667, val accuracy: 0.772000\n",
      "Loss: 1.036495, Train accuracy: 0.986556, val accuracy: 0.764000\n",
      "Loss: 1.047924, Train accuracy: 0.992333, val accuracy: 0.776000\n",
      "Loss: 1.035963, Train accuracy: 0.991889, val accuracy: 0.770000\n",
      "Loss: 1.069003, Train accuracy: 0.989667, val accuracy: 0.775000\n",
      "Loss: 1.037557, Train accuracy: 0.988000, val accuracy: 0.770000\n",
      "Loss: 1.044374, Train accuracy: 0.993111, val accuracy: 0.776000\n",
      "Loss: 1.180310, Train accuracy: 0.993222, val accuracy: 0.768000\n",
      "Loss: 1.087622, Train accuracy: 0.993667, val accuracy: 0.771000\n",
      "Loss: 1.046761, Train accuracy: 0.992333, val accuracy: 0.768000\n",
      "Loss: 1.065690, Train accuracy: 0.990222, val accuracy: 0.763000\n",
      "Loss: 1.074189, Train accuracy: 0.992778, val accuracy: 0.770000\n",
      "Loss: 1.086815, Train accuracy: 0.992444, val accuracy: 0.767000\n",
      "Loss: 1.136955, Train accuracy: 0.991111, val accuracy: 0.769000\n",
      "Loss: 1.078636, Train accuracy: 0.994000, val accuracy: 0.774000\n",
      "Loss: 1.057234, Train accuracy: 0.994556, val accuracy: 0.773000\n",
      "Loss: 1.101220, Train accuracy: 0.992222, val accuracy: 0.769000\n",
      "Loss: 1.107425, Train accuracy: 0.990778, val accuracy: 0.773000\n",
      "Loss: 1.070890, Train accuracy: 0.994667, val accuracy: 0.768000\n",
      "Loss: 1.122450, Train accuracy: 0.994111, val accuracy: 0.768000\n",
      "Loss: 1.084301, Train accuracy: 0.994667, val accuracy: 0.766000\n",
      "Loss: 1.094076, Train accuracy: 0.994444, val accuracy: 0.775000\n",
      "Loss: 1.149318, Train accuracy: 0.994000, val accuracy: 0.772000\n",
      "Loss: 1.122942, Train accuracy: 0.995111, val accuracy: 0.763000\n",
      "Loss: 1.132174, Train accuracy: 0.995333, val accuracy: 0.773000\n",
      "Loss: 1.088521, Train accuracy: 0.994556, val accuracy: 0.769000\n",
      "Loss: 1.146746, Train accuracy: 0.995556, val accuracy: 0.776000\n",
      "Loss: 1.114881, Train accuracy: 0.995000, val accuracy: 0.767000\n",
      "Loss: 1.142508, Train accuracy: 0.997000, val accuracy: 0.768000\n",
      "Loss: 1.151902, Train accuracy: 0.994889, val accuracy: 0.769000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.108107, Train accuracy: 0.996444, val accuracy: 0.769000\n",
      "Loss: 1.138912, Train accuracy: 0.985889, val accuracy: 0.763000\n",
      "Loss: 1.135799, Train accuracy: 0.996667, val accuracy: 0.771000\n",
      "Loss: 1.185617, Train accuracy: 0.995333, val accuracy: 0.763000\n",
      "Loss: 1.127131, Train accuracy: 0.994444, val accuracy: 0.766000\n",
      "Loss: 1.157934, Train accuracy: 0.994667, val accuracy: 0.769000\n",
      "Loss: 1.134339, Train accuracy: 0.997778, val accuracy: 0.767000\n",
      "Loss: 1.159198, Train accuracy: 0.997333, val accuracy: 0.768000\n",
      "Loss: 1.118127, Train accuracy: 0.997333, val accuracy: 0.768000\n",
      "Loss: 1.138280, Train accuracy: 0.996556, val accuracy: 0.767000\n",
      "Loss: 1.127307, Train accuracy: 0.996556, val accuracy: 0.772000\n",
      "Loss: 1.147812, Train accuracy: 0.997556, val accuracy: 0.771000\n",
      "Loss: 1.173816, Train accuracy: 0.997111, val accuracy: 0.772000\n",
      "Loss: 1.237419, Train accuracy: 0.997333, val accuracy: 0.773000\n",
      "Loss: 1.170510, Train accuracy: 0.997778, val accuracy: 0.772000\n",
      "Loss: 1.158082, Train accuracy: 0.997667, val accuracy: 0.770000\n",
      "Loss: 1.186554, Train accuracy: 0.997667, val accuracy: 0.771000\n",
      "Loss: 1.163805, Train accuracy: 0.997667, val accuracy: 0.771000\n",
      "Loss: 1.160125, Train accuracy: 0.997667, val accuracy: 0.767000\n",
      "Loss: 2.277336, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251663, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308620, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234662, Train accuracy: 0.198222, val accuracy: 0.205000\n",
      "Loss: 2.265530, Train accuracy: 0.259778, val accuracy: 0.256000\n",
      "Loss: 1.906431, Train accuracy: 0.283778, val accuracy: 0.284000\n",
      "Loss: 1.699209, Train accuracy: 0.346556, val accuracy: 0.353000\n",
      "Loss: 1.739309, Train accuracy: 0.420111, val accuracy: 0.413000\n",
      "Loss: 1.517815, Train accuracy: 0.467667, val accuracy: 0.461000\n",
      "Loss: 1.555380, Train accuracy: 0.508111, val accuracy: 0.512000\n",
      "Loss: 1.423844, Train accuracy: 0.563889, val accuracy: 0.556000\n",
      "Loss: 1.314484, Train accuracy: 0.589000, val accuracy: 0.573000\n",
      "Loss: 1.505023, Train accuracy: 0.618333, val accuracy: 0.608000\n",
      "Loss: 1.275066, Train accuracy: 0.630111, val accuracy: 0.630000\n",
      "Loss: 1.405767, Train accuracy: 0.644222, val accuracy: 0.637000\n",
      "Loss: 1.088586, Train accuracy: 0.660889, val accuracy: 0.653000\n",
      "Loss: 1.117823, Train accuracy: 0.692889, val accuracy: 0.678000\n",
      "Loss: 1.180563, Train accuracy: 0.696556, val accuracy: 0.676000\n",
      "Loss: 0.805623, Train accuracy: 0.692222, val accuracy: 0.671000\n",
      "Loss: 0.893679, Train accuracy: 0.719667, val accuracy: 0.695000\n",
      "Loss: 1.352884, Train accuracy: 0.733444, val accuracy: 0.693000\n",
      "Loss: 1.126245, Train accuracy: 0.738222, val accuracy: 0.694000\n",
      "Loss: 1.022773, Train accuracy: 0.748667, val accuracy: 0.700000\n",
      "Loss: 1.326120, Train accuracy: 0.754444, val accuracy: 0.710000\n",
      "Loss: 0.911095, Train accuracy: 0.763000, val accuracy: 0.716000\n",
      "Loss: 1.031652, Train accuracy: 0.765333, val accuracy: 0.720000\n",
      "Loss: 0.938248, Train accuracy: 0.772333, val accuracy: 0.726000\n",
      "Loss: 0.860071, Train accuracy: 0.780889, val accuracy: 0.724000\n",
      "Loss: 1.079096, Train accuracy: 0.785000, val accuracy: 0.719000\n",
      "Loss: 1.193996, Train accuracy: 0.792778, val accuracy: 0.727000\n",
      "Loss: 0.991199, Train accuracy: 0.804444, val accuracy: 0.730000\n",
      "Loss: 0.954632, Train accuracy: 0.807889, val accuracy: 0.736000\n",
      "Loss: 1.016901, Train accuracy: 0.811222, val accuracy: 0.735000\n",
      "Loss: 0.712119, Train accuracy: 0.820111, val accuracy: 0.735000\n",
      "Loss: 0.973115, Train accuracy: 0.826778, val accuracy: 0.736000\n",
      "Loss: 1.054019, Train accuracy: 0.823333, val accuracy: 0.736000\n",
      "Loss: 0.915597, Train accuracy: 0.832111, val accuracy: 0.743000\n",
      "Loss: 0.636373, Train accuracy: 0.833556, val accuracy: 0.736000\n",
      "Loss: 0.690029, Train accuracy: 0.843667, val accuracy: 0.747000\n",
      "Loss: 0.585170, Train accuracy: 0.847889, val accuracy: 0.751000\n",
      "Loss: 0.898135, Train accuracy: 0.855111, val accuracy: 0.742000\n",
      "Loss: 0.700393, Train accuracy: 0.852111, val accuracy: 0.747000\n",
      "Loss: 0.790824, Train accuracy: 0.857667, val accuracy: 0.750000\n",
      "Loss: 0.920873, Train accuracy: 0.866333, val accuracy: 0.758000\n",
      "Loss: 0.756594, Train accuracy: 0.866333, val accuracy: 0.754000\n",
      "Loss: 1.060878, Train accuracy: 0.864333, val accuracy: 0.740000\n",
      "Loss: 0.838501, Train accuracy: 0.870556, val accuracy: 0.745000\n",
      "Loss: 0.675257, Train accuracy: 0.879778, val accuracy: 0.757000\n",
      "Loss: 0.699872, Train accuracy: 0.881111, val accuracy: 0.756000\n",
      "Loss: 0.727632, Train accuracy: 0.882000, val accuracy: 0.749000\n",
      "Loss: 0.898576, Train accuracy: 0.860889, val accuracy: 0.744000\n",
      "Loss: 0.813378, Train accuracy: 0.896333, val accuracy: 0.762000\n",
      "Loss: 1.025189, Train accuracy: 0.884333, val accuracy: 0.759000\n",
      "Loss: 0.812292, Train accuracy: 0.901778, val accuracy: 0.760000\n",
      "Loss: 0.812421, Train accuracy: 0.906111, val accuracy: 0.760000\n",
      "Loss: 0.817545, Train accuracy: 0.907000, val accuracy: 0.756000\n",
      "Loss: 0.903644, Train accuracy: 0.906222, val accuracy: 0.762000\n",
      "Loss: 0.802854, Train accuracy: 0.898333, val accuracy: 0.753000\n",
      "Loss: 0.821145, Train accuracy: 0.912111, val accuracy: 0.754000\n",
      "Loss: 0.935965, Train accuracy: 0.921111, val accuracy: 0.761000\n",
      "Loss: 0.715171, Train accuracy: 0.905778, val accuracy: 0.741000\n",
      "Loss: 0.851768, Train accuracy: 0.916333, val accuracy: 0.768000\n",
      "Loss: 0.807121, Train accuracy: 0.917667, val accuracy: 0.762000\n",
      "Loss: 0.639978, Train accuracy: 0.920444, val accuracy: 0.761000\n",
      "Loss: 0.725860, Train accuracy: 0.911778, val accuracy: 0.757000\n",
      "Loss: 0.788446, Train accuracy: 0.927556, val accuracy: 0.761000\n",
      "Loss: 0.828054, Train accuracy: 0.934000, val accuracy: 0.765000\n",
      "Loss: 0.704006, Train accuracy: 0.933778, val accuracy: 0.770000\n",
      "Loss: 0.905022, Train accuracy: 0.929444, val accuracy: 0.766000\n",
      "Loss: 0.812074, Train accuracy: 0.936889, val accuracy: 0.764000\n",
      "Loss: 1.020374, Train accuracy: 0.918889, val accuracy: 0.755000\n",
      "Loss: 1.016481, Train accuracy: 0.936000, val accuracy: 0.764000\n",
      "Loss: 0.815939, Train accuracy: 0.924667, val accuracy: 0.759000\n",
      "Loss: 0.931423, Train accuracy: 0.945000, val accuracy: 0.758000\n",
      "Loss: 0.811691, Train accuracy: 0.943111, val accuracy: 0.761000\n",
      "Loss: 0.835513, Train accuracy: 0.954444, val accuracy: 0.769000\n",
      "Loss: 0.777490, Train accuracy: 0.953556, val accuracy: 0.767000\n",
      "Loss: 0.941856, Train accuracy: 0.939000, val accuracy: 0.765000\n",
      "Loss: 0.849314, Train accuracy: 0.954222, val accuracy: 0.756000\n",
      "Loss: 0.765105, Train accuracy: 0.956444, val accuracy: 0.768000\n",
      "Loss: 0.910710, Train accuracy: 0.951222, val accuracy: 0.761000\n",
      "Loss: 0.884523, Train accuracy: 0.955222, val accuracy: 0.770000\n",
      "Loss: 0.799908, Train accuracy: 0.961333, val accuracy: 0.768000\n",
      "Loss: 0.722290, Train accuracy: 0.961000, val accuracy: 0.759000\n",
      "Loss: 0.733158, Train accuracy: 0.948778, val accuracy: 0.765000\n",
      "Loss: 0.848388, Train accuracy: 0.961111, val accuracy: 0.762000\n",
      "Loss: 0.828989, Train accuracy: 0.968222, val accuracy: 0.776000\n",
      "Loss: 0.845765, Train accuracy: 0.956556, val accuracy: 0.762000\n",
      "Loss: 0.947982, Train accuracy: 0.964889, val accuracy: 0.775000\n",
      "Loss: 0.781820, Train accuracy: 0.969111, val accuracy: 0.765000\n",
      "Loss: 0.863734, Train accuracy: 0.966556, val accuracy: 0.768000\n",
      "Loss: 0.835060, Train accuracy: 0.967778, val accuracy: 0.760000\n",
      "Loss: 0.892075, Train accuracy: 0.968889, val accuracy: 0.762000\n",
      "Loss: 1.150702, Train accuracy: 0.970556, val accuracy: 0.766000\n",
      "Loss: 0.929314, Train accuracy: 0.972444, val accuracy: 0.768000\n",
      "Loss: 0.826570, Train accuracy: 0.968444, val accuracy: 0.760000\n",
      "Loss: 0.910031, Train accuracy: 0.975333, val accuracy: 0.765000\n",
      "Loss: 0.800365, Train accuracy: 0.973333, val accuracy: 0.764000\n",
      "Loss: 0.844082, Train accuracy: 0.978556, val accuracy: 0.775000\n",
      "Loss: 0.810836, Train accuracy: 0.975444, val accuracy: 0.770000\n",
      "Loss: 1.120139, Train accuracy: 0.960556, val accuracy: 0.759000\n",
      "Loss: 0.970734, Train accuracy: 0.977222, val accuracy: 0.761000\n",
      "Loss: 0.901759, Train accuracy: 0.977556, val accuracy: 0.766000\n",
      "Loss: 0.861872, Train accuracy: 0.979222, val accuracy: 0.766000\n",
      "Loss: 0.834703, Train accuracy: 0.978111, val accuracy: 0.770000\n",
      "Loss: 0.867828, Train accuracy: 0.980778, val accuracy: 0.771000\n",
      "Loss: 0.882243, Train accuracy: 0.971333, val accuracy: 0.758000\n",
      "Loss: 0.878494, Train accuracy: 0.973333, val accuracy: 0.768000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.843818, Train accuracy: 0.984889, val accuracy: 0.773000\n",
      "Loss: 0.924006, Train accuracy: 0.979778, val accuracy: 0.763000\n",
      "Loss: 0.888828, Train accuracy: 0.982000, val accuracy: 0.770000\n",
      "Loss: 0.945986, Train accuracy: 0.978667, val accuracy: 0.767000\n",
      "Loss: 0.913684, Train accuracy: 0.981333, val accuracy: 0.761000\n",
      "Loss: 0.992029, Train accuracy: 0.984889, val accuracy: 0.760000\n",
      "Loss: 1.028353, Train accuracy: 0.971222, val accuracy: 0.760000\n",
      "Loss: 0.932652, Train accuracy: 0.983556, val accuracy: 0.772000\n",
      "Loss: 0.913407, Train accuracy: 0.983444, val accuracy: 0.768000\n",
      "Loss: 1.086616, Train accuracy: 0.985333, val accuracy: 0.771000\n",
      "Loss: 0.958728, Train accuracy: 0.987222, val accuracy: 0.766000\n",
      "Loss: 0.944368, Train accuracy: 0.989333, val accuracy: 0.773000\n",
      "Loss: 0.986295, Train accuracy: 0.989222, val accuracy: 0.773000\n",
      "Loss: 0.979485, Train accuracy: 0.989000, val accuracy: 0.771000\n",
      "Loss: 1.015069, Train accuracy: 0.987333, val accuracy: 0.774000\n",
      "Loss: 1.089211, Train accuracy: 0.981778, val accuracy: 0.766000\n",
      "Loss: 0.980156, Train accuracy: 0.989444, val accuracy: 0.767000\n",
      "Loss: 0.923094, Train accuracy: 0.988889, val accuracy: 0.760000\n",
      "Loss: 0.960299, Train accuracy: 0.985444, val accuracy: 0.770000\n",
      "Loss: 0.962027, Train accuracy: 0.991667, val accuracy: 0.767000\n",
      "Loss: 0.993124, Train accuracy: 0.991111, val accuracy: 0.771000\n",
      "Loss: 0.995404, Train accuracy: 0.984111, val accuracy: 0.765000\n",
      "Loss: 0.975203, Train accuracy: 0.992667, val accuracy: 0.775000\n",
      "Loss: 1.015335, Train accuracy: 0.993222, val accuracy: 0.768000\n",
      "Loss: 0.974823, Train accuracy: 0.989667, val accuracy: 0.776000\n",
      "Loss: 0.940296, Train accuracy: 0.993111, val accuracy: 0.773000\n",
      "Loss: 0.989574, Train accuracy: 0.992111, val accuracy: 0.764000\n",
      "Loss: 0.979994, Train accuracy: 0.992000, val accuracy: 0.764000\n",
      "Loss: 1.023360, Train accuracy: 0.992222, val accuracy: 0.768000\n",
      "Loss: 1.037661, Train accuracy: 0.987889, val accuracy: 0.766000\n",
      "Loss: 0.976448, Train accuracy: 0.994667, val accuracy: 0.766000\n",
      "Loss: 0.999940, Train accuracy: 0.992778, val accuracy: 0.763000\n",
      "Loss: 1.022034, Train accuracy: 0.995333, val accuracy: 0.777000\n",
      "Loss: 1.058860, Train accuracy: 0.994000, val accuracy: 0.770000\n",
      "Loss: 0.998240, Train accuracy: 0.995111, val accuracy: 0.766000\n",
      "Loss: 1.008893, Train accuracy: 0.994444, val accuracy: 0.770000\n",
      "Loss: 0.996850, Train accuracy: 0.995556, val accuracy: 0.773000\n",
      "Loss: 1.017558, Train accuracy: 0.995667, val accuracy: 0.770000\n",
      "Loss: 0.992688, Train accuracy: 0.995778, val accuracy: 0.776000\n",
      "Loss: 0.988421, Train accuracy: 0.994444, val accuracy: 0.768000\n",
      "Loss: 1.013798, Train accuracy: 0.993333, val accuracy: 0.770000\n",
      "Loss: 1.058167, Train accuracy: 0.995667, val accuracy: 0.765000\n",
      "Loss: 1.037002, Train accuracy: 0.994778, val accuracy: 0.771000\n",
      "Loss: 1.034769, Train accuracy: 0.997333, val accuracy: 0.774000\n",
      "Loss: 1.048969, Train accuracy: 0.996667, val accuracy: 0.767000\n",
      "Loss: 1.029675, Train accuracy: 0.995444, val accuracy: 0.764000\n",
      "Loss: 1.014906, Train accuracy: 0.994222, val accuracy: 0.766000\n",
      "Loss: 1.049779, Train accuracy: 0.997333, val accuracy: 0.778000\n",
      "Loss: 1.070767, Train accuracy: 0.993889, val accuracy: 0.767000\n",
      "Loss: 1.033802, Train accuracy: 0.997667, val accuracy: 0.763000\n",
      "Loss: 1.059256, Train accuracy: 0.997111, val accuracy: 0.772000\n",
      "Loss: 1.126305, Train accuracy: 0.995444, val accuracy: 0.762000\n",
      "Loss: 1.067765, Train accuracy: 0.997000, val accuracy: 0.772000\n",
      "Loss: 1.038521, Train accuracy: 0.994222, val accuracy: 0.764000\n",
      "Loss: 1.065865, Train accuracy: 0.997444, val accuracy: 0.768000\n",
      "Loss: 1.081758, Train accuracy: 0.998222, val accuracy: 0.770000\n",
      "Loss: 1.087901, Train accuracy: 0.998444, val accuracy: 0.773000\n",
      "Loss: 1.164500, Train accuracy: 0.998111, val accuracy: 0.767000\n",
      "Loss: 1.071034, Train accuracy: 0.997889, val accuracy: 0.773000\n",
      "Loss: 1.065151, Train accuracy: 0.997444, val accuracy: 0.770000\n",
      "Loss: 1.073744, Train accuracy: 0.997333, val accuracy: 0.771000\n",
      "Loss: 1.110513, Train accuracy: 0.996222, val accuracy: 0.771000\n",
      "Loss: 1.067473, Train accuracy: 0.998444, val accuracy: 0.771000\n",
      "Loss: 1.071985, Train accuracy: 0.998889, val accuracy: 0.773000\n",
      "Loss: 1.103316, Train accuracy: 0.998444, val accuracy: 0.775000\n",
      "Loss: 1.084031, Train accuracy: 0.998444, val accuracy: 0.763000\n",
      "Loss: 1.133075, Train accuracy: 0.998556, val accuracy: 0.767000\n",
      "Loss: 1.085841, Train accuracy: 0.998556, val accuracy: 0.772000\n",
      "Loss: 1.096625, Train accuracy: 0.998667, val accuracy: 0.768000\n",
      "Loss: 1.118847, Train accuracy: 0.998667, val accuracy: 0.769000\n",
      "Loss: 1.117827, Train accuracy: 0.998556, val accuracy: 0.767000\n",
      "Loss: 1.104233, Train accuracy: 0.998778, val accuracy: 0.776000\n",
      "Loss: 1.098369, Train accuracy: 0.998889, val accuracy: 0.775000\n",
      "Loss: 1.108635, Train accuracy: 0.999111, val accuracy: 0.771000\n",
      "Loss: 1.112211, Train accuracy: 0.997556, val accuracy: 0.772000\n",
      "Loss: 1.106539, Train accuracy: 0.999000, val accuracy: 0.767000\n",
      "Loss: 1.125274, Train accuracy: 0.998889, val accuracy: 0.770000\n",
      "Loss: 1.123825, Train accuracy: 0.999333, val accuracy: 0.771000\n",
      "Loss: 1.167266, Train accuracy: 0.997333, val accuracy: 0.772000\n",
      "Loss: 1.126083, Train accuracy: 0.999333, val accuracy: 0.777000\n",
      "Loss: 1.136186, Train accuracy: 0.999222, val accuracy: 0.770000\n",
      "Loss: 1.126869, Train accuracy: 0.999333, val accuracy: 0.768000\n",
      "Loss: 1.125897, Train accuracy: 0.998556, val accuracy: 0.767000\n",
      "Loss: 1.132984, Train accuracy: 0.999444, val accuracy: 0.765000\n",
      "Loss: 1.136360, Train accuracy: 0.999222, val accuracy: 0.776000\n",
      "Loss: 1.121775, Train accuracy: 0.999222, val accuracy: 0.768000\n",
      "Loss: 1.134202, Train accuracy: 0.999333, val accuracy: 0.770000\n",
      "Loss: 1.133149, Train accuracy: 0.999222, val accuracy: 0.770000\n",
      "Loss: 1.134691, Train accuracy: 0.999111, val accuracy: 0.771000\n",
      "Loss: 1.158447, Train accuracy: 0.999444, val accuracy: 0.772000\n",
      "Loss: 1.149501, Train accuracy: 0.999333, val accuracy: 0.765000\n",
      "Loss: 1.139016, Train accuracy: 0.999000, val accuracy: 0.767000\n",
      "Loss: 2.290693, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259183, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252909, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253716, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277070, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259745, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.196837, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228701, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283155, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249754, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205727, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225284, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.190925, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.133757, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290204, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239666, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252383, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237521, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.210114, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234481, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225836, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.186460, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287405, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201052, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276198, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.151486, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.220520, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.160602, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225476, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.402999, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.173522, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.171430, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238774, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.142904, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.177512, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.392821, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.087267, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.186777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214978, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286155, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.170688, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.193628, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181412, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.102300, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.913968, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.132254, Train accuracy: 0.202333, val accuracy: 0.212000\n",
      "Loss: 2.147895, Train accuracy: 0.207333, val accuracy: 0.214000\n",
      "Loss: 2.366327, Train accuracy: 0.212222, val accuracy: 0.220000\n",
      "Loss: 1.875367, Train accuracy: 0.217000, val accuracy: 0.220000\n",
      "Loss: 2.145735, Train accuracy: 0.221444, val accuracy: 0.228000\n",
      "Loss: 2.119830, Train accuracy: 0.225222, val accuracy: 0.230000\n",
      "Loss: 2.084963, Train accuracy: 0.232556, val accuracy: 0.239000\n",
      "Loss: 1.861178, Train accuracy: 0.235556, val accuracy: 0.238000\n",
      "Loss: 2.184173, Train accuracy: 0.241556, val accuracy: 0.244000\n",
      "Loss: 1.939924, Train accuracy: 0.245556, val accuracy: 0.244000\n",
      "Loss: 1.986803, Train accuracy: 0.248667, val accuracy: 0.249000\n",
      "Loss: 1.974824, Train accuracy: 0.254000, val accuracy: 0.252000\n",
      "Loss: 2.114963, Train accuracy: 0.256000, val accuracy: 0.250000\n",
      "Loss: 1.962451, Train accuracy: 0.260222, val accuracy: 0.254000\n",
      "Loss: 2.128961, Train accuracy: 0.262111, val accuracy: 0.257000\n",
      "Loss: 2.013330, Train accuracy: 0.267000, val accuracy: 0.265000\n",
      "Loss: 1.944627, Train accuracy: 0.268667, val accuracy: 0.265000\n",
      "Loss: 2.042466, Train accuracy: 0.269778, val accuracy: 0.267000\n",
      "Loss: 1.991932, Train accuracy: 0.271667, val accuracy: 0.272000\n",
      "Loss: 1.878603, Train accuracy: 0.273333, val accuracy: 0.273000\n",
      "Loss: 2.097925, Train accuracy: 0.277222, val accuracy: 0.278000\n",
      "Loss: 1.932040, Train accuracy: 0.277222, val accuracy: 0.280000\n",
      "Loss: 2.144094, Train accuracy: 0.280111, val accuracy: 0.286000\n",
      "Loss: 1.850699, Train accuracy: 0.284444, val accuracy: 0.291000\n",
      "Loss: 1.972989, Train accuracy: 0.288111, val accuracy: 0.291000\n",
      "Loss: 1.988580, Train accuracy: 0.291222, val accuracy: 0.296000\n",
      "Loss: 2.015283, Train accuracy: 0.295556, val accuracy: 0.301000\n",
      "Loss: 2.169491, Train accuracy: 0.300222, val accuracy: 0.309000\n",
      "Loss: 1.978923, Train accuracy: 0.305556, val accuracy: 0.310000\n",
      "Loss: 1.912414, Train accuracy: 0.313333, val accuracy: 0.315000\n",
      "Loss: 1.989826, Train accuracy: 0.318000, val accuracy: 0.326000\n",
      "Loss: 1.940435, Train accuracy: 0.325556, val accuracy: 0.332000\n",
      "Loss: 2.018603, Train accuracy: 0.330111, val accuracy: 0.336000\n",
      "Loss: 1.828660, Train accuracy: 0.338111, val accuracy: 0.345000\n",
      "Loss: 1.947192, Train accuracy: 0.344333, val accuracy: 0.350000\n",
      "Loss: 1.958739, Train accuracy: 0.352111, val accuracy: 0.351000\n",
      "Loss: 2.011213, Train accuracy: 0.358111, val accuracy: 0.357000\n",
      "Loss: 1.999733, Train accuracy: 0.364333, val accuracy: 0.362000\n",
      "Loss: 1.861331, Train accuracy: 0.368000, val accuracy: 0.365000\n",
      "Loss: 1.946410, Train accuracy: 0.375111, val accuracy: 0.369000\n",
      "Loss: 1.957424, Train accuracy: 0.377556, val accuracy: 0.368000\n",
      "Loss: 1.831006, Train accuracy: 0.383333, val accuracy: 0.369000\n",
      "Loss: 1.905913, Train accuracy: 0.387667, val accuracy: 0.375000\n",
      "Loss: 1.827000, Train accuracy: 0.391778, val accuracy: 0.379000\n",
      "Loss: 2.072606, Train accuracy: 0.394889, val accuracy: 0.383000\n",
      "Loss: 1.898634, Train accuracy: 0.398556, val accuracy: 0.381000\n",
      "Loss: 1.725679, Train accuracy: 0.400556, val accuracy: 0.388000\n",
      "Loss: 1.645995, Train accuracy: 0.405111, val accuracy: 0.393000\n",
      "Loss: 1.477945, Train accuracy: 0.409889, val accuracy: 0.398000\n",
      "Loss: 1.684666, Train accuracy: 0.412667, val accuracy: 0.399000\n",
      "Loss: 1.906542, Train accuracy: 0.416667, val accuracy: 0.407000\n",
      "Loss: 1.764322, Train accuracy: 0.422333, val accuracy: 0.411000\n",
      "Loss: 1.786018, Train accuracy: 0.426556, val accuracy: 0.415000\n",
      "Loss: 1.644230, Train accuracy: 0.432889, val accuracy: 0.426000\n",
      "Loss: 1.673579, Train accuracy: 0.436333, val accuracy: 0.426000\n",
      "Loss: 1.708559, Train accuracy: 0.440444, val accuracy: 0.437000\n",
      "Loss: 1.759192, Train accuracy: 0.446111, val accuracy: 0.439000\n",
      "Loss: 1.734934, Train accuracy: 0.450889, val accuracy: 0.446000\n",
      "Loss: 1.547074, Train accuracy: 0.455556, val accuracy: 0.444000\n",
      "Loss: 1.858673, Train accuracy: 0.461000, val accuracy: 0.450000\n",
      "Loss: 1.669020, Train accuracy: 0.466889, val accuracy: 0.458000\n",
      "Loss: 1.676136, Train accuracy: 0.472111, val accuracy: 0.460000\n",
      "Loss: 1.626831, Train accuracy: 0.477000, val accuracy: 0.464000\n",
      "Loss: 1.690241, Train accuracy: 0.481000, val accuracy: 0.472000\n",
      "Loss: 1.486892, Train accuracy: 0.485222, val accuracy: 0.475000\n",
      "Loss: 1.446839, Train accuracy: 0.490000, val accuracy: 0.482000\n",
      "Loss: 1.643697, Train accuracy: 0.494556, val accuracy: 0.487000\n",
      "Loss: 1.462412, Train accuracy: 0.500667, val accuracy: 0.495000\n",
      "Loss: 1.564861, Train accuracy: 0.504778, val accuracy: 0.496000\n",
      "Loss: 1.218251, Train accuracy: 0.508556, val accuracy: 0.498000\n",
      "Loss: 1.415424, Train accuracy: 0.514222, val accuracy: 0.502000\n",
      "Loss: 1.374320, Train accuracy: 0.516111, val accuracy: 0.515000\n",
      "Loss: 1.588812, Train accuracy: 0.521000, val accuracy: 0.514000\n",
      "Loss: 1.289704, Train accuracy: 0.522889, val accuracy: 0.526000\n",
      "Loss: 1.627038, Train accuracy: 0.528889, val accuracy: 0.521000\n",
      "Loss: 1.735356, Train accuracy: 0.533000, val accuracy: 0.531000\n",
      "Loss: 1.599487, Train accuracy: 0.535556, val accuracy: 0.530000\n",
      "Loss: 1.478878, Train accuracy: 0.540778, val accuracy: 0.540000\n",
      "Loss: 1.348554, Train accuracy: 0.543333, val accuracy: 0.542000\n",
      "Loss: 1.395763, Train accuracy: 0.545778, val accuracy: 0.546000\n",
      "Loss: 1.482342, Train accuracy: 0.550000, val accuracy: 0.548000\n",
      "Loss: 1.346876, Train accuracy: 0.554778, val accuracy: 0.551000\n",
      "Loss: 1.373295, Train accuracy: 0.557000, val accuracy: 0.548000\n",
      "Loss: 1.308845, Train accuracy: 0.559556, val accuracy: 0.549000\n",
      "Loss: 1.266876, Train accuracy: 0.564111, val accuracy: 0.552000\n",
      "Loss: 1.406006, Train accuracy: 0.564111, val accuracy: 0.546000\n",
      "Loss: 1.478806, Train accuracy: 0.570111, val accuracy: 0.553000\n",
      "Loss: 1.227682, Train accuracy: 0.569222, val accuracy: 0.557000\n",
      "Loss: 1.452621, Train accuracy: 0.575667, val accuracy: 0.555000\n",
      "Loss: 1.425614, Train accuracy: 0.575667, val accuracy: 0.556000\n",
      "Loss: 1.311358, Train accuracy: 0.577556, val accuracy: 0.558000\n",
      "Loss: 1.248012, Train accuracy: 0.580111, val accuracy: 0.564000\n",
      "Loss: 1.325514, Train accuracy: 0.583111, val accuracy: 0.559000\n",
      "Loss: 1.349837, Train accuracy: 0.586889, val accuracy: 0.558000\n",
      "Loss: 1.382364, Train accuracy: 0.589000, val accuracy: 0.563000\n",
      "Loss: 1.105826, Train accuracy: 0.590444, val accuracy: 0.563000\n",
      "Loss: 1.347477, Train accuracy: 0.594444, val accuracy: 0.564000\n",
      "Loss: 1.447840, Train accuracy: 0.596111, val accuracy: 0.566000\n",
      "Loss: 1.466809, Train accuracy: 0.598111, val accuracy: 0.573000\n",
      "Loss: 1.331909, Train accuracy: 0.599667, val accuracy: 0.569000\n",
      "Loss: 1.334678, Train accuracy: 0.603333, val accuracy: 0.572000\n",
      "Loss: 1.209048, Train accuracy: 0.604111, val accuracy: 0.580000\n",
      "Loss: 1.268644, Train accuracy: 0.607000, val accuracy: 0.587000\n",
      "Loss: 1.378977, Train accuracy: 0.608667, val accuracy: 0.585000\n",
      "Loss: 1.473599, Train accuracy: 0.610667, val accuracy: 0.584000\n",
      "Loss: 1.312333, Train accuracy: 0.611444, val accuracy: 0.591000\n",
      "Loss: 1.352618, Train accuracy: 0.613556, val accuracy: 0.585000\n",
      "Loss: 1.185586, Train accuracy: 0.616333, val accuracy: 0.588000\n",
      "Loss: 1.400532, Train accuracy: 0.618444, val accuracy: 0.594000\n",
      "Loss: 1.440253, Train accuracy: 0.621333, val accuracy: 0.598000\n",
      "Loss: 1.125288, Train accuracy: 0.624889, val accuracy: 0.594000\n",
      "Loss: 1.235229, Train accuracy: 0.625778, val accuracy: 0.602000\n",
      "Loss: 1.509730, Train accuracy: 0.629444, val accuracy: 0.600000\n",
      "Loss: 1.098702, Train accuracy: 0.632222, val accuracy: 0.604000\n",
      "Loss: 1.105578, Train accuracy: 0.634000, val accuracy: 0.605000\n",
      "Loss: 1.094638, Train accuracy: 0.637667, val accuracy: 0.607000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.256587, Train accuracy: 0.638222, val accuracy: 0.609000\n",
      "Loss: 1.366939, Train accuracy: 0.639667, val accuracy: 0.617000\n",
      "Loss: 1.184028, Train accuracy: 0.642556, val accuracy: 0.616000\n",
      "Loss: 1.141763, Train accuracy: 0.643778, val accuracy: 0.619000\n",
      "Loss: 1.278612, Train accuracy: 0.644333, val accuracy: 0.621000\n",
      "Loss: 1.162393, Train accuracy: 0.647222, val accuracy: 0.623000\n",
      "Loss: 1.419614, Train accuracy: 0.648778, val accuracy: 0.625000\n",
      "Loss: 1.369153, Train accuracy: 0.649000, val accuracy: 0.633000\n",
      "Loss: 1.378569, Train accuracy: 0.653889, val accuracy: 0.630000\n",
      "Loss: 1.095403, Train accuracy: 0.655778, val accuracy: 0.634000\n",
      "Loss: 1.372972, Train accuracy: 0.655889, val accuracy: 0.634000\n",
      "Loss: 1.463794, Train accuracy: 0.659111, val accuracy: 0.635000\n",
      "Loss: 1.176970, Train accuracy: 0.659556, val accuracy: 0.641000\n",
      "Loss: 1.323112, Train accuracy: 0.661556, val accuracy: 0.651000\n",
      "Loss: 1.182100, Train accuracy: 0.663444, val accuracy: 0.641000\n",
      "Loss: 0.866635, Train accuracy: 0.664222, val accuracy: 0.651000\n",
      "Loss: 1.167447, Train accuracy: 0.666000, val accuracy: 0.651000\n",
      "Loss: 1.238307, Train accuracy: 0.668556, val accuracy: 0.653000\n",
      "Loss: 1.079793, Train accuracy: 0.670778, val accuracy: 0.659000\n",
      "Loss: 1.071081, Train accuracy: 0.670778, val accuracy: 0.652000\n",
      "Loss: 1.393172, Train accuracy: 0.672111, val accuracy: 0.655000\n",
      "Loss: 1.202739, Train accuracy: 0.673889, val accuracy: 0.661000\n",
      "Loss: 1.308555, Train accuracy: 0.676222, val accuracy: 0.659000\n",
      "Loss: 1.292502, Train accuracy: 0.679000, val accuracy: 0.663000\n",
      "Loss: 1.222247, Train accuracy: 0.676556, val accuracy: 0.667000\n",
      "Loss: 0.914367, Train accuracy: 0.679111, val accuracy: 0.666000\n",
      "Loss: 1.177400, Train accuracy: 0.680333, val accuracy: 0.668000\n",
      "Loss: 1.106036, Train accuracy: 0.681667, val accuracy: 0.672000\n",
      "Loss: 1.097513, Train accuracy: 0.683333, val accuracy: 0.676000\n",
      "Loss: 1.177847, Train accuracy: 0.683778, val accuracy: 0.674000\n",
      "Loss: 1.240983, Train accuracy: 0.687000, val accuracy: 0.675000\n",
      "Loss: 1.122512, Train accuracy: 0.687667, val accuracy: 0.678000\n",
      "Loss: 1.192745, Train accuracy: 0.689667, val accuracy: 0.676000\n",
      "Loss: 1.242190, Train accuracy: 0.689222, val accuracy: 0.682000\n",
      "Loss: 1.077139, Train accuracy: 0.691556, val accuracy: 0.679000\n",
      "Loss: 0.902460, Train accuracy: 0.693778, val accuracy: 0.678000\n",
      "Loss: 1.361176, Train accuracy: 0.694000, val accuracy: 0.679000\n",
      "Loss: 1.023007, Train accuracy: 0.694111, val accuracy: 0.678000\n",
      "Loss: 2.288406, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288121, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286873, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253277, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279387, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254262, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216240, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230150, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217067, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256858, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246539, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.171308, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.192637, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.306636, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298622, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.172194, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.137890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.328586, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.326015, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.222188, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266570, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177682, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224395, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214204, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288372, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274902, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.387957, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.166203, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.149008, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.194035, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287719, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245569, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.151145, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236733, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308318, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.185197, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.165999, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.190349, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290540, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.151362, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.101344, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.067563, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.132998, Train accuracy: 0.199111, val accuracy: 0.209000\n",
      "Loss: 2.026885, Train accuracy: 0.203333, val accuracy: 0.211000\n",
      "Loss: 2.065339, Train accuracy: 0.208222, val accuracy: 0.213000\n",
      "Loss: 2.189853, Train accuracy: 0.214000, val accuracy: 0.223000\n",
      "Loss: 2.155090, Train accuracy: 0.220889, val accuracy: 0.226000\n",
      "Loss: 2.228884, Train accuracy: 0.226000, val accuracy: 0.230000\n",
      "Loss: 2.104125, Train accuracy: 0.231222, val accuracy: 0.233000\n",
      "Loss: 2.092280, Train accuracy: 0.238000, val accuracy: 0.243000\n",
      "Loss: 2.128856, Train accuracy: 0.241444, val accuracy: 0.246000\n",
      "Loss: 2.079188, Train accuracy: 0.248889, val accuracy: 0.253000\n",
      "Loss: 2.143631, Train accuracy: 0.251000, val accuracy: 0.252000\n",
      "Loss: 2.056922, Train accuracy: 0.255778, val accuracy: 0.253000\n",
      "Loss: 2.100561, Train accuracy: 0.260000, val accuracy: 0.258000\n",
      "Loss: 2.075304, Train accuracy: 0.264222, val accuracy: 0.259000\n",
      "Loss: 2.080811, Train accuracy: 0.269222, val accuracy: 0.265000\n",
      "Loss: 1.941625, Train accuracy: 0.272000, val accuracy: 0.270000\n",
      "Loss: 2.025632, Train accuracy: 0.273889, val accuracy: 0.275000\n",
      "Loss: 2.006386, Train accuracy: 0.275667, val accuracy: 0.277000\n",
      "Loss: 1.932047, Train accuracy: 0.277889, val accuracy: 0.279000\n",
      "Loss: 2.098289, Train accuracy: 0.280889, val accuracy: 0.283000\n",
      "Loss: 1.873997, Train accuracy: 0.285111, val accuracy: 0.287000\n",
      "Loss: 2.085073, Train accuracy: 0.287444, val accuracy: 0.291000\n",
      "Loss: 1.876686, Train accuracy: 0.291778, val accuracy: 0.295000\n",
      "Loss: 2.004874, Train accuracy: 0.295889, val accuracy: 0.301000\n",
      "Loss: 2.003432, Train accuracy: 0.300333, val accuracy: 0.305000\n",
      "Loss: 1.952130, Train accuracy: 0.303556, val accuracy: 0.308000\n",
      "Loss: 1.991210, Train accuracy: 0.307778, val accuracy: 0.316000\n",
      "Loss: 2.137932, Train accuracy: 0.311667, val accuracy: 0.322000\n",
      "Loss: 2.035059, Train accuracy: 0.317000, val accuracy: 0.322000\n",
      "Loss: 1.982388, Train accuracy: 0.323778, val accuracy: 0.327000\n",
      "Loss: 2.080783, Train accuracy: 0.331556, val accuracy: 0.332000\n",
      "Loss: 1.717376, Train accuracy: 0.340556, val accuracy: 0.341000\n",
      "Loss: 1.833187, Train accuracy: 0.348556, val accuracy: 0.344000\n",
      "Loss: 1.743469, Train accuracy: 0.356333, val accuracy: 0.355000\n",
      "Loss: 1.739453, Train accuracy: 0.361222, val accuracy: 0.366000\n",
      "Loss: 1.738308, Train accuracy: 0.370444, val accuracy: 0.369000\n",
      "Loss: 1.657655, Train accuracy: 0.375667, val accuracy: 0.372000\n",
      "Loss: 1.852663, Train accuracy: 0.381000, val accuracy: 0.369000\n",
      "Loss: 1.902566, Train accuracy: 0.388000, val accuracy: 0.372000\n",
      "Loss: 1.763626, Train accuracy: 0.394556, val accuracy: 0.377000\n",
      "Loss: 1.673790, Train accuracy: 0.397111, val accuracy: 0.382000\n",
      "Loss: 1.634887, Train accuracy: 0.402000, val accuracy: 0.382000\n",
      "Loss: 1.786552, Train accuracy: 0.407778, val accuracy: 0.389000\n",
      "Loss: 1.658351, Train accuracy: 0.414889, val accuracy: 0.397000\n",
      "Loss: 2.023068, Train accuracy: 0.419000, val accuracy: 0.401000\n",
      "Loss: 1.744740, Train accuracy: 0.423556, val accuracy: 0.408000\n",
      "Loss: 1.557083, Train accuracy: 0.428333, val accuracy: 0.414000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.678970, Train accuracy: 0.433000, val accuracy: 0.422000\n",
      "Loss: 1.750278, Train accuracy: 0.439333, val accuracy: 0.428000\n",
      "Loss: 1.716772, Train accuracy: 0.443333, val accuracy: 0.435000\n",
      "Loss: 1.608569, Train accuracy: 0.448444, val accuracy: 0.438000\n",
      "Loss: 1.687357, Train accuracy: 0.453667, val accuracy: 0.447000\n",
      "Loss: 1.616045, Train accuracy: 0.458111, val accuracy: 0.444000\n",
      "Loss: 1.640554, Train accuracy: 0.464000, val accuracy: 0.450000\n",
      "Loss: 1.886783, Train accuracy: 0.467333, val accuracy: 0.456000\n",
      "Loss: 1.644750, Train accuracy: 0.473222, val accuracy: 0.460000\n",
      "Loss: 1.427133, Train accuracy: 0.477000, val accuracy: 0.464000\n",
      "Loss: 1.475314, Train accuracy: 0.483222, val accuracy: 0.474000\n",
      "Loss: 1.699687, Train accuracy: 0.486333, val accuracy: 0.469000\n",
      "Loss: 1.804300, Train accuracy: 0.491333, val accuracy: 0.477000\n",
      "Loss: 1.571920, Train accuracy: 0.495778, val accuracy: 0.484000\n",
      "Loss: 1.490425, Train accuracy: 0.500667, val accuracy: 0.490000\n",
      "Loss: 1.620685, Train accuracy: 0.502000, val accuracy: 0.494000\n",
      "Loss: 1.313302, Train accuracy: 0.508333, val accuracy: 0.500000\n",
      "Loss: 1.351548, Train accuracy: 0.508667, val accuracy: 0.501000\n",
      "Loss: 1.768349, Train accuracy: 0.514667, val accuracy: 0.508000\n",
      "Loss: 1.598859, Train accuracy: 0.517000, val accuracy: 0.528000\n",
      "Loss: 1.800047, Train accuracy: 0.519889, val accuracy: 0.520000\n",
      "Loss: 1.645574, Train accuracy: 0.526222, val accuracy: 0.523000\n",
      "Loss: 1.609847, Train accuracy: 0.528667, val accuracy: 0.530000\n",
      "Loss: 1.412974, Train accuracy: 0.533222, val accuracy: 0.524000\n",
      "Loss: 1.530986, Train accuracy: 0.537222, val accuracy: 0.530000\n",
      "Loss: 1.303894, Train accuracy: 0.538222, val accuracy: 0.529000\n",
      "Loss: 1.595129, Train accuracy: 0.544333, val accuracy: 0.538000\n",
      "Loss: 1.581803, Train accuracy: 0.545222, val accuracy: 0.536000\n",
      "Loss: 1.390519, Train accuracy: 0.552556, val accuracy: 0.541000\n",
      "Loss: 1.264065, Train accuracy: 0.554889, val accuracy: 0.544000\n",
      "Loss: 1.383382, Train accuracy: 0.560778, val accuracy: 0.551000\n",
      "Loss: 1.449529, Train accuracy: 0.561667, val accuracy: 0.550000\n",
      "Loss: 1.409239, Train accuracy: 0.566667, val accuracy: 0.556000\n",
      "Loss: 1.309744, Train accuracy: 0.568556, val accuracy: 0.559000\n",
      "Loss: 1.405936, Train accuracy: 0.572333, val accuracy: 0.562000\n",
      "Loss: 1.416053, Train accuracy: 0.578222, val accuracy: 0.568000\n",
      "Loss: 1.332346, Train accuracy: 0.580333, val accuracy: 0.567000\n",
      "Loss: 1.414380, Train accuracy: 0.583667, val accuracy: 0.567000\n",
      "Loss: 1.330102, Train accuracy: 0.587333, val accuracy: 0.572000\n",
      "Loss: 1.403688, Train accuracy: 0.590333, val accuracy: 0.576000\n",
      "Loss: 1.337702, Train accuracy: 0.591556, val accuracy: 0.575000\n",
      "Loss: 1.400726, Train accuracy: 0.595778, val accuracy: 0.577000\n",
      "Loss: 1.588218, Train accuracy: 0.598667, val accuracy: 0.578000\n",
      "Loss: 1.226870, Train accuracy: 0.602778, val accuracy: 0.580000\n",
      "Loss: 1.596422, Train accuracy: 0.604556, val accuracy: 0.582000\n",
      "Loss: 1.254937, Train accuracy: 0.606111, val accuracy: 0.586000\n",
      "Loss: 1.203306, Train accuracy: 0.608667, val accuracy: 0.590000\n",
      "Loss: 1.323056, Train accuracy: 0.613333, val accuracy: 0.595000\n",
      "Loss: 1.319341, Train accuracy: 0.615778, val accuracy: 0.599000\n",
      "Loss: 1.423691, Train accuracy: 0.616889, val accuracy: 0.598000\n",
      "Loss: 1.407546, Train accuracy: 0.620667, val accuracy: 0.603000\n",
      "Loss: 1.246994, Train accuracy: 0.621333, val accuracy: 0.604000\n",
      "Loss: 1.262787, Train accuracy: 0.625000, val accuracy: 0.611000\n",
      "Loss: 1.374509, Train accuracy: 0.628000, val accuracy: 0.610000\n",
      "Loss: 1.096884, Train accuracy: 0.628889, val accuracy: 0.610000\n",
      "Loss: 1.385554, Train accuracy: 0.630667, val accuracy: 0.612000\n",
      "Loss: 1.403396, Train accuracy: 0.633000, val accuracy: 0.615000\n",
      "Loss: 1.604671, Train accuracy: 0.634889, val accuracy: 0.619000\n",
      "Loss: 0.844414, Train accuracy: 0.632889, val accuracy: 0.623000\n",
      "Loss: 1.150610, Train accuracy: 0.636556, val accuracy: 0.629000\n",
      "Loss: 1.006418, Train accuracy: 0.638111, val accuracy: 0.623000\n",
      "Loss: 1.199285, Train accuracy: 0.640000, val accuracy: 0.633000\n",
      "Loss: 1.151085, Train accuracy: 0.644111, val accuracy: 0.630000\n",
      "Loss: 1.107446, Train accuracy: 0.644778, val accuracy: 0.635000\n",
      "Loss: 0.823393, Train accuracy: 0.646000, val accuracy: 0.641000\n",
      "Loss: 1.325284, Train accuracy: 0.648778, val accuracy: 0.639000\n",
      "Loss: 1.306332, Train accuracy: 0.650889, val accuracy: 0.640000\n",
      "Loss: 1.109352, Train accuracy: 0.652778, val accuracy: 0.638000\n",
      "Loss: 1.317985, Train accuracy: 0.654444, val accuracy: 0.643000\n",
      "Loss: 1.306664, Train accuracy: 0.656667, val accuracy: 0.647000\n",
      "Loss: 1.049762, Train accuracy: 0.658000, val accuracy: 0.646000\n",
      "Loss: 1.162209, Train accuracy: 0.660444, val accuracy: 0.645000\n",
      "Loss: 1.270416, Train accuracy: 0.662778, val accuracy: 0.648000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-df73915ccfdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                   batch_size=batch_size, learning_rate_decay=learning_rate_decay)\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mval_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mbest_val_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/neural-networks/nn-limbo/Task2/pchizhov/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             train_accuracy = self.compute_accuracy(self.dataset.train_X,\n\u001b[0;32m--> 115\u001b[0;31m                                                    self.dataset.train_y)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             val_accuracy = self.compute_accuracy(self.dataset.val_X,\n",
      "\u001b[0;32m~/Documents/python/neural-networks/nn-limbo/Task2/pchizhov/trainer.py\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mbatch_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mpred_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/neural-networks/nn-limbo/Task2/pchizhov/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     55\u001b[0m           \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/neural-networks/nn-limbo/Task2/pchizhov/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.9\n",
    "hidden_layer_size = [64, 128, 256]\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "best_rate = None\n",
    "best_size = None\n",
    "best_histories = []\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "for rate in learning_rates:\n",
    "    for size in hidden_layer_size:\n",
    "        \n",
    "\n",
    "        model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = size, reg = reg_strength)\n",
    "        dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "        trainer = Trainer(model, dataset, SGD(), learning_rate=rate, num_epochs=num_epochs, \n",
    "                  batch_size=batch_size, learning_rate_decay=learning_rate_decay)\n",
    "\n",
    "        loss_history, train_history, val_history = trainer.fit()\n",
    "        if not best_val_accuracy or val_history[-1] > best_val_accuracy:\n",
    "            best_val_accuracy = val_history[-1]\n",
    "            best_classifier = trainer\n",
    "            best_rate = rate\n",
    "            best_size = size\n",
    "            best_histories = [loss_history, train_history, val_history]\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)\n",
    "print('best learning rate: %f' % best_rate)\n",
    "print('best hidden layer size:', best_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.939159, Train accuracy: 0.328222, val accuracy: 0.337000\n",
      "Loss: 1.933515, Train accuracy: 0.506000, val accuracy: 0.480000\n",
      "Loss: 1.910135, Train accuracy: 0.545111, val accuracy: 0.554000\n",
      "Loss: 1.400863, Train accuracy: 0.610111, val accuracy: 0.594000\n",
      "Loss: 1.175751, Train accuracy: 0.661000, val accuracy: 0.643000\n",
      "Loss: 1.617995, Train accuracy: 0.674778, val accuracy: 0.638000\n",
      "Loss: 1.581073, Train accuracy: 0.722333, val accuracy: 0.667000\n",
      "Loss: 2.298744, Train accuracy: 0.656222, val accuracy: 0.629000\n",
      "Loss: 1.530187, Train accuracy: 0.753333, val accuracy: 0.707000\n",
      "Loss: 1.890433, Train accuracy: 0.754000, val accuracy: 0.694000\n",
      "Loss: 1.745593, Train accuracy: 0.751444, val accuracy: 0.700000\n",
      "Loss: 1.745943, Train accuracy: 0.777000, val accuracy: 0.706000\n",
      "Loss: 2.575704, Train accuracy: 0.792222, val accuracy: 0.718000\n",
      "Loss: 2.475237, Train accuracy: 0.749556, val accuracy: 0.671000\n",
      "Loss: 2.145660, Train accuracy: 0.808889, val accuracy: 0.709000\n",
      "Loss: 2.094047, Train accuracy: 0.817667, val accuracy: 0.719000\n",
      "Loss: 2.421384, Train accuracy: 0.781333, val accuracy: 0.693000\n",
      "Loss: 2.016780, Train accuracy: 0.829111, val accuracy: 0.710000\n",
      "Loss: 2.594097, Train accuracy: 0.800556, val accuracy: 0.678000\n",
      "Loss: 2.607937, Train accuracy: 0.796222, val accuracy: 0.685000\n",
      "Loss: 3.325219, Train accuracy: 0.814000, val accuracy: 0.703000\n",
      "Loss: 2.596563, Train accuracy: 0.847444, val accuracy: 0.723000\n",
      "Loss: 2.616613, Train accuracy: 0.864222, val accuracy: 0.732000\n",
      "Loss: 3.076306, Train accuracy: 0.809333, val accuracy: 0.705000\n",
      "Loss: 2.680815, Train accuracy: 0.870111, val accuracy: 0.748000\n",
      "Loss: 3.173677, Train accuracy: 0.863889, val accuracy: 0.732000\n",
      "Loss: 3.210122, Train accuracy: 0.822889, val accuracy: 0.698000\n",
      "Loss: 3.734704, Train accuracy: 0.769000, val accuracy: 0.651000\n",
      "Loss: 3.176492, Train accuracy: 0.824889, val accuracy: 0.705000\n",
      "Loss: 3.167728, Train accuracy: 0.876778, val accuracy: 0.726000\n",
      "Loss: 3.205242, Train accuracy: 0.862222, val accuracy: 0.723000\n",
      "Loss: 3.354709, Train accuracy: 0.853444, val accuracy: 0.698000\n",
      "Loss: 3.416368, Train accuracy: 0.866667, val accuracy: 0.727000\n",
      "Loss: 3.494519, Train accuracy: 0.893667, val accuracy: 0.720000\n",
      "Loss: 3.504317, Train accuracy: 0.909333, val accuracy: 0.750000\n",
      "Loss: 3.723966, Train accuracy: 0.862222, val accuracy: 0.695000\n",
      "Loss: 4.288034, Train accuracy: 0.858222, val accuracy: 0.720000\n",
      "Loss: 3.924102, Train accuracy: 0.892111, val accuracy: 0.732000\n",
      "Loss: 3.759280, Train accuracy: 0.901778, val accuracy: 0.752000\n",
      "Loss: 3.965667, Train accuracy: 0.833000, val accuracy: 0.717000\n",
      "Loss: 3.982836, Train accuracy: 0.900333, val accuracy: 0.727000\n",
      "Loss: 4.372254, Train accuracy: 0.884556, val accuracy: 0.730000\n",
      "Loss: 4.039290, Train accuracy: 0.895111, val accuracy: 0.722000\n",
      "Loss: 4.254377, Train accuracy: 0.882222, val accuracy: 0.728000\n",
      "Loss: 4.305797, Train accuracy: 0.928111, val accuracy: 0.748000\n",
      "Loss: 4.113050, Train accuracy: 0.917111, val accuracy: 0.735000\n",
      "Loss: 4.689223, Train accuracy: 0.876778, val accuracy: 0.707000\n",
      "Loss: 4.799110, Train accuracy: 0.914444, val accuracy: 0.742000\n",
      "Loss: 4.578505, Train accuracy: 0.925111, val accuracy: 0.747000\n",
      "Loss: 5.050467, Train accuracy: 0.925111, val accuracy: 0.739000\n",
      "Loss: 4.519619, Train accuracy: 0.938778, val accuracy: 0.753000\n",
      "Loss: 4.607117, Train accuracy: 0.935778, val accuracy: 0.749000\n",
      "Loss: 5.318323, Train accuracy: 0.867556, val accuracy: 0.719000\n",
      "Loss: 5.295199, Train accuracy: 0.899778, val accuracy: 0.725000\n",
      "Loss: 4.917158, Train accuracy: 0.944556, val accuracy: 0.736000\n",
      "Loss: 5.222238, Train accuracy: 0.917111, val accuracy: 0.723000\n",
      "Loss: 5.024477, Train accuracy: 0.947444, val accuracy: 0.752000\n",
      "Loss: 5.136453, Train accuracy: 0.948889, val accuracy: 0.732000\n",
      "Loss: 5.682425, Train accuracy: 0.926111, val accuracy: 0.728000\n",
      "Loss: 5.449013, Train accuracy: 0.950333, val accuracy: 0.740000\n",
      "Loss: 5.201558, Train accuracy: 0.935222, val accuracy: 0.740000\n",
      "Loss: 5.244926, Train accuracy: 0.940222, val accuracy: 0.741000\n",
      "Loss: 5.742010, Train accuracy: 0.921444, val accuracy: 0.742000\n",
      "Loss: 5.443165, Train accuracy: 0.959444, val accuracy: 0.757000\n",
      "Loss: 5.583153, Train accuracy: 0.923111, val accuracy: 0.736000\n",
      "Loss: 5.679431, Train accuracy: 0.883778, val accuracy: 0.714000\n",
      "Loss: 5.772980, Train accuracy: 0.937333, val accuracy: 0.720000\n",
      "Loss: 5.758684, Train accuracy: 0.959333, val accuracy: 0.761000\n",
      "Loss: 5.600863, Train accuracy: 0.962556, val accuracy: 0.749000\n",
      "Loss: 5.738155, Train accuracy: 0.931556, val accuracy: 0.739000\n",
      "Loss: 5.667123, Train accuracy: 0.950778, val accuracy: 0.735000\n",
      "Loss: 6.067560, Train accuracy: 0.921111, val accuracy: 0.734000\n",
      "Loss: 6.088443, Train accuracy: 0.949333, val accuracy: 0.737000\n",
      "Loss: 6.042969, Train accuracy: 0.955111, val accuracy: 0.746000\n",
      "Loss: 5.989742, Train accuracy: 0.938000, val accuracy: 0.740000\n",
      "Loss: 5.910835, Train accuracy: 0.953222, val accuracy: 0.740000\n",
      "Loss: 6.748410, Train accuracy: 0.917000, val accuracy: 0.729000\n",
      "Loss: 6.116959, Train accuracy: 0.937333, val accuracy: 0.736000\n",
      "Loss: 6.346536, Train accuracy: 0.938556, val accuracy: 0.733000\n",
      "Loss: 6.140256, Train accuracy: 0.949222, val accuracy: 0.756000\n",
      "Loss: 6.204409, Train accuracy: 0.941889, val accuracy: 0.732000\n",
      "Loss: 6.435311, Train accuracy: 0.953333, val accuracy: 0.760000\n",
      "Loss: 6.963476, Train accuracy: 0.922556, val accuracy: 0.724000\n",
      "Loss: 6.347668, Train accuracy: 0.977111, val accuracy: 0.755000\n",
      "Loss: 6.501769, Train accuracy: 0.957333, val accuracy: 0.746000\n",
      "Loss: 6.330991, Train accuracy: 0.954889, val accuracy: 0.749000\n",
      "Loss: 6.396950, Train accuracy: 0.960667, val accuracy: 0.745000\n",
      "Loss: 6.385801, Train accuracy: 0.978444, val accuracy: 0.755000\n",
      "Loss: 6.503786, Train accuracy: 0.977000, val accuracy: 0.762000\n",
      "Loss: 7.304612, Train accuracy: 0.857333, val accuracy: 0.705000\n",
      "Loss: 6.932002, Train accuracy: 0.885556, val accuracy: 0.720000\n",
      "Loss: 6.775169, Train accuracy: 0.945111, val accuracy: 0.729000\n",
      "Loss: 7.130092, Train accuracy: 0.927000, val accuracy: 0.722000\n",
      "Loss: 6.898440, Train accuracy: 0.964000, val accuracy: 0.744000\n",
      "Loss: 7.399588, Train accuracy: 0.956000, val accuracy: 0.736000\n",
      "Loss: 6.846158, Train accuracy: 0.985556, val accuracy: 0.755000\n",
      "Loss: 6.973317, Train accuracy: 0.973444, val accuracy: 0.749000\n",
      "Loss: 6.716005, Train accuracy: 0.981667, val accuracy: 0.745000\n",
      "Loss: 6.715410, Train accuracy: 0.981778, val accuracy: 0.758000\n",
      "Loss: 6.760723, Train accuracy: 0.982000, val accuracy: 0.761000\n",
      "Loss: 6.855028, Train accuracy: 0.970889, val accuracy: 0.764000\n",
      "Loss: 6.749241, Train accuracy: 0.979111, val accuracy: 0.754000\n",
      "Loss: 7.482358, Train accuracy: 0.921222, val accuracy: 0.727000\n",
      "Loss: 7.103856, Train accuracy: 0.944889, val accuracy: 0.747000\n",
      "Loss: 7.014887, Train accuracy: 0.976444, val accuracy: 0.759000\n",
      "Loss: 7.018208, Train accuracy: 0.981667, val accuracy: 0.759000\n",
      "Loss: 6.919407, Train accuracy: 0.983444, val accuracy: 0.759000\n",
      "Loss: 6.989385, Train accuracy: 0.976222, val accuracy: 0.755000\n",
      "Loss: 6.935153, Train accuracy: 0.980889, val accuracy: 0.754000\n",
      "Loss: 6.930332, Train accuracy: 0.975778, val accuracy: 0.754000\n",
      "Loss: 6.989244, Train accuracy: 0.962000, val accuracy: 0.750000\n",
      "Loss: 6.944395, Train accuracy: 0.969222, val accuracy: 0.745000\n",
      "Loss: 7.089232, Train accuracy: 0.887667, val accuracy: 0.707000\n",
      "Loss: 7.231289, Train accuracy: 0.954333, val accuracy: 0.739000\n",
      "Loss: 7.255775, Train accuracy: 0.975556, val accuracy: 0.750000\n",
      "Loss: 7.090285, Train accuracy: 0.987111, val accuracy: 0.762000\n",
      "Loss: 7.067146, Train accuracy: 0.983889, val accuracy: 0.753000\n",
      "Loss: 7.073466, Train accuracy: 0.990000, val accuracy: 0.765000\n",
      "Loss: 7.101650, Train accuracy: 0.979333, val accuracy: 0.747000\n",
      "Loss: 7.148688, Train accuracy: 0.971333, val accuracy: 0.725000\n",
      "Loss: 7.055299, Train accuracy: 0.988000, val accuracy: 0.759000\n",
      "Loss: 7.067080, Train accuracy: 0.989333, val accuracy: 0.761000\n",
      "Loss: 7.110132, Train accuracy: 0.970111, val accuracy: 0.745000\n",
      "Loss: 7.050580, Train accuracy: 0.967889, val accuracy: 0.745000\n",
      "Loss: 8.045145, Train accuracy: 0.821222, val accuracy: 0.669000\n",
      "Loss: 7.534728, Train accuracy: 0.934889, val accuracy: 0.732000\n",
      "Loss: 7.470569, Train accuracy: 0.981222, val accuracy: 0.753000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7.445815, Train accuracy: 0.975333, val accuracy: 0.737000\n",
      "Loss: 7.407264, Train accuracy: 0.979222, val accuracy: 0.743000\n",
      "Loss: 7.470319, Train accuracy: 0.991333, val accuracy: 0.759000\n",
      "Loss: 7.394354, Train accuracy: 0.976778, val accuracy: 0.756000\n",
      "Loss: 7.370875, Train accuracy: 0.989000, val accuracy: 0.750000\n",
      "Loss: 7.341843, Train accuracy: 0.994333, val accuracy: 0.752000\n",
      "Loss: 7.353243, Train accuracy: 0.992000, val accuracy: 0.754000\n",
      "Loss: 7.320846, Train accuracy: 0.996444, val accuracy: 0.754000\n",
      "Loss: 7.376686, Train accuracy: 0.994000, val accuracy: 0.761000\n",
      "Loss: 7.312771, Train accuracy: 0.995111, val accuracy: 0.750000\n",
      "Loss: 7.260625, Train accuracy: 0.987000, val accuracy: 0.750000\n",
      "Loss: 7.398279, Train accuracy: 0.988000, val accuracy: 0.768000\n",
      "Loss: 7.320367, Train accuracy: 0.978667, val accuracy: 0.763000\n",
      "Loss: 7.492864, Train accuracy: 0.972111, val accuracy: 0.732000\n",
      "Loss: 7.395122, Train accuracy: 0.969333, val accuracy: 0.739000\n",
      "Loss: 7.292865, Train accuracy: 0.986111, val accuracy: 0.749000\n",
      "Loss: 7.396838, Train accuracy: 0.978000, val accuracy: 0.750000\n",
      "Loss: 7.297575, Train accuracy: 0.990000, val accuracy: 0.740000\n",
      "Loss: 7.352528, Train accuracy: 0.993889, val accuracy: 0.749000\n",
      "Loss: 7.986276, Train accuracy: 0.876667, val accuracy: 0.701000\n",
      "Loss: 8.013520, Train accuracy: 0.912444, val accuracy: 0.700000\n",
      "Loss: 7.644599, Train accuracy: 0.950333, val accuracy: 0.722000\n",
      "Loss: 7.633925, Train accuracy: 0.948111, val accuracy: 0.728000\n",
      "Loss: 7.594843, Train accuracy: 0.985778, val accuracy: 0.750000\n",
      "Loss: 7.606680, Train accuracy: 0.963444, val accuracy: 0.727000\n",
      "Loss: 7.555061, Train accuracy: 0.990889, val accuracy: 0.755000\n",
      "Loss: 7.505058, Train accuracy: 0.995222, val accuracy: 0.751000\n",
      "Loss: 7.482282, Train accuracy: 0.996667, val accuracy: 0.766000\n",
      "Loss: 7.465024, Train accuracy: 0.981556, val accuracy: 0.739000\n",
      "Loss: 7.461517, Train accuracy: 0.994111, val accuracy: 0.746000\n",
      "Loss: 7.434572, Train accuracy: 0.997444, val accuracy: 0.760000\n",
      "Loss: 7.411268, Train accuracy: 0.997222, val accuracy: 0.756000\n",
      "Loss: 7.393547, Train accuracy: 0.997778, val accuracy: 0.760000\n",
      "Loss: 7.420322, Train accuracy: 0.998556, val accuracy: 0.763000\n",
      "Loss: 7.342829, Train accuracy: 0.996556, val accuracy: 0.764000\n",
      "Loss: 7.321850, Train accuracy: 0.997889, val accuracy: 0.760000\n",
      "Loss: 7.289202, Train accuracy: 0.998778, val accuracy: 0.759000\n",
      "Loss: 7.275015, Train accuracy: 0.998444, val accuracy: 0.761000\n",
      "Loss: 7.246439, Train accuracy: 0.998889, val accuracy: 0.762000\n",
      "Loss: 7.218331, Train accuracy: 0.998000, val accuracy: 0.766000\n",
      "Loss: 7.192556, Train accuracy: 0.998889, val accuracy: 0.759000\n",
      "Loss: 7.173428, Train accuracy: 0.999000, val accuracy: 0.763000\n",
      "Loss: 8.729971, Train accuracy: 0.838556, val accuracy: 0.648000\n",
      "Loss: 7.344866, Train accuracy: 0.915111, val accuracy: 0.727000\n",
      "Loss: 7.405055, Train accuracy: 0.968778, val accuracy: 0.738000\n",
      "Loss: 7.440356, Train accuracy: 0.966111, val accuracy: 0.752000\n",
      "Loss: 7.429294, Train accuracy: 0.991111, val accuracy: 0.763000\n",
      "Loss: 7.433895, Train accuracy: 0.992111, val accuracy: 0.760000\n",
      "Loss: 7.495408, Train accuracy: 0.974333, val accuracy: 0.740000\n",
      "Loss: 7.362679, Train accuracy: 0.997444, val accuracy: 0.769000\n",
      "Loss: 7.340347, Train accuracy: 0.997889, val accuracy: 0.766000\n",
      "Loss: 7.324276, Train accuracy: 0.997556, val accuracy: 0.756000\n",
      "Loss: 7.298997, Train accuracy: 0.998222, val accuracy: 0.767000\n",
      "Loss: 7.319848, Train accuracy: 0.996556, val accuracy: 0.754000\n",
      "Loss: 7.284448, Train accuracy: 0.991222, val accuracy: 0.746000\n",
      "Loss: 7.453136, Train accuracy: 0.977444, val accuracy: 0.739000\n",
      "Loss: 7.326318, Train accuracy: 0.992778, val accuracy: 0.761000\n",
      "Loss: 7.394692, Train accuracy: 0.990667, val accuracy: 0.759000\n",
      "Loss: 7.349447, Train accuracy: 0.970111, val accuracy: 0.749000\n",
      "Loss: 7.325584, Train accuracy: 0.993444, val accuracy: 0.761000\n",
      "Loss: 7.304410, Train accuracy: 0.998000, val accuracy: 0.763000\n",
      "Loss: 7.315366, Train accuracy: 0.997778, val accuracy: 0.759000\n",
      "Loss: 7.290410, Train accuracy: 0.997667, val accuracy: 0.758000\n",
      "Loss: 7.241827, Train accuracy: 0.998778, val accuracy: 0.761000\n",
      "Loss: 7.215388, Train accuracy: 0.999111, val accuracy: 0.760000\n",
      "Loss: 7.191413, Train accuracy: 0.998889, val accuracy: 0.762000\n",
      "Loss: 7.161661, Train accuracy: 0.998778, val accuracy: 0.763000\n",
      "Loss: 7.371000, Train accuracy: 0.989222, val accuracy: 0.754000\n",
      "Loss: 7.146137, Train accuracy: 0.999222, val accuracy: 0.765000\n",
      "Loss: 7.093043, Train accuracy: 0.998889, val accuracy: 0.773000\n",
      "Loss: 7.072178, Train accuracy: 0.999000, val accuracy: 0.767000\n",
      "Loss: 7.045600, Train accuracy: 0.998889, val accuracy: 0.766000\n",
      "Loss: 7.015353, Train accuracy: 0.999111, val accuracy: 0.766000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x106541048>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 128, reg = reg_strength)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-2, num_epochs=num_epochs, \n",
    "                  batch_size=batch_size, learning_rate_decay=learning_rate_decay)\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "best_classifier = model\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.739000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
